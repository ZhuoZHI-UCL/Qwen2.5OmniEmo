[INFO|2025-10-22 12:20:35] llamafactory.cli:143 >> Initializing 4 distributed tasks at: 127.0.0.1:34089
W1022 12:20:37.377000 3100070 site-packages/torch/distributed/run.py:766] 
W1022 12:20:37.377000 3100070 site-packages/torch/distributed/run.py:766] *****************************************
W1022 12:20:37.377000 3100070 site-packages/torch/distributed/run.py:766] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1022 12:20:37.377000 3100070 site-packages/torch/distributed/run.py:766] *****************************************
[2025-10-22 12:20:42,347] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[WARNING|2025-10-22 12:20:42] llamafactory.extras.misc:154 >> Version checking has been disabled, may lead to unexpected behaviors.
[2025-10-22 12:20:43,266] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-10-22 12:20:43,296] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-10-22 12:20:43,331] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-10-22 12:20:44,006] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-10-22 12:20:44,699] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-10-22 12:20:44,741] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-10-22 12:20:44,744] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-10-22 12:20:45,490] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-10-22 12:20:45,956] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-10-22 12:20:45,969] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-10-22 12:20:45,969] [INFO] [comm.py:852:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-10-22 12:20:46,005] [INFO] [comm.py:821:init_distributed] cdb=None
[INFO|2025-10-22 12:20:51] llamafactory.hparams.parser:143 >> Set `ddp_find_unused_parameters` to False in DDP training since LoRA is enabled.
[INFO|2025-10-22 12:20:51] llamafactory.hparams.parser:423 >> Process rank: 0, world size: 4, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
[INFO|tokenization_utils_base.py:2021] 2025-10-22 12:20:51,051 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-10-22 12:20:51,051 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-10-22 12:20:51,051 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-10-22 12:20:51,051 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-10-22 12:20:51,051 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-10-22 12:20:51,051 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-10-22 12:20:51,051 >> loading file chat_template.jinja
[INFO|2025-10-22 12:20:51] llamafactory.hparams.parser:423 >> Process rank: 2, world size: 4, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
[INFO|2025-10-22 12:20:51] llamafactory.hparams.parser:423 >> Process rank: 3, world size: 4, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
[INFO|2025-10-22 12:20:51] llamafactory.hparams.parser:423 >> Process rank: 1, world size: 4, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
[INFO|tokenization_utils_base.py:2299] 2025-10-22 12:20:51,456 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-10-22 12:20:51,456 >> loading configuration file /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/hf_cache/models--Qwen--Qwen2.5-Omni-7B/snapshots/ae9e1690543ffd5c0221dc27f79834d0294cba00/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-10-22 12:20:51,466 >> loading configuration file /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/hf_cache/models--Qwen--Qwen2.5-Omni-7B/snapshots/ae9e1690543ffd5c0221dc27f79834d0294cba00/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-10-22 12:20:51,466 >> Image processor Qwen2VLImageProcessor {
  "chunk_length": 300,
  "dither": 0.0,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "feature_size": 128,
  "hop_length": 160,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "n_fft": 400,
  "n_samples": 4800000,
  "nb_max_frames": 30000,
  "padding_side": "right",
  "padding_value": 0.0,
  "patch_size": 14,
  "processor_class": "Qwen2_5OmniProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_attention_mask": true,
  "sampling_rate": 16000,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[WARNING|logging.py:328] 2025-10-22 12:20:51,467 >> You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.
[INFO|video_processing_utils.py:627] 2025-10-22 12:20:51,467 >> loading configuration file /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/hf_cache/models--Qwen--Qwen2.5-Omni-7B/snapshots/ae9e1690543ffd5c0221dc27f79834d0294cba00/preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-10-22 12:20:51,467 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "chunk_length": 300,
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "dither": 0.0,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "feature_extractor_type": "WhisperFeatureExtractor",
  "feature_size": 128,
  "hop_length": 160,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "n_fft": 400,
  "n_samples": 4800000,
  "nb_max_frames": 30000,
  "padding_side": "right",
  "padding_value": 0.0,
  "patch_size": 14,
  "processor_class": "Qwen2_5OmniProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_attention_mask": true,
  "sampling_rate": 16000,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|feature_extraction_utils.py:548] 2025-10-22 12:20:51,472 >> loading configuration file /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/hf_cache/models--Qwen--Qwen2.5-Omni-7B/snapshots/ae9e1690543ffd5c0221dc27f79834d0294cba00/preprocessor_config.json
[INFO|feature_extraction_utils.py:597] 2025-10-22 12:20:51,473 >> Feature extractor WhisperFeatureExtractor {
  "chunk_length": 300,
  "dither": 0.0,
  "feature_extractor_type": "WhisperFeatureExtractor",
  "feature_size": 128,
  "hop_length": 160,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "n_fft": 400,
  "n_samples": 4800000,
  "nb_max_frames": 30000,
  "padding_side": "right",
  "padding_value": 0.0,
  "patch_size": 14,
  "processor_class": "Qwen2_5OmniProcessor",
  "return_attention_mask": true,
  "sampling_rate": 16000,
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-10-22 12:20:51,474 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-10-22 12:20:51,474 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-10-22 12:20:51,474 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-10-22 12:20:51,474 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-10-22 12:20:51,474 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-10-22 12:20:51,474 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-10-22 12:20:51,474 >> loading file chat_template.jinja
You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.
You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.
You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.
[INFO|tokenization_utils_base.py:2299] 2025-10-22 12:20:51,907 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}
Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}
[INFO|processing_utils.py:990] 2025-10-22 12:20:52,401 >> Processor Qwen2_5OmniProcessor:
- image_processor: Qwen2VLImageProcessor {
  "chunk_length": 300,
  "dither": 0.0,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "feature_size": 128,
  "hop_length": 160,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "n_fft": 400,
  "n_samples": 4800000,
  "nb_max_frames": 30000,
  "padding_side": "right",
  "padding_value": 0.0,
  "patch_size": 14,
  "processor_class": "Qwen2_5OmniProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_attention_mask": true,
  "sampling_rate": 16000,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "chunk_length": 300,
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "dither": 0.0,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "feature_extractor_type": "WhisperFeatureExtractor",
  "feature_size": 128,
  "hop_length": 160,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "n_fft": 400,
  "n_samples": 4800000,
  "nb_max_frames": 30000,
  "padding_side": "right",
  "padding_value": 0.0,
  "patch_size": 14,
  "processor_class": "Qwen2_5OmniProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_attention_mask": true,
  "sampling_rate": 16000,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

- feature_extractor: WhisperFeatureExtractor {
  "chunk_length": 300,
  "dither": 0.0,
  "feature_extractor_type": "WhisperFeatureExtractor",
  "feature_size": 128,
  "hop_length": 160,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "n_fft": 400,
  "n_samples": 4800000,
  "nb_max_frames": 30000,
  "padding_side": "right",
  "padding_value": 0.0,
  "patch_size": 14,
  "processor_class": "Qwen2_5OmniProcessor",
  "return_attention_mask": true,
  "sampling_rate": 16000,
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='/home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/hf_cache/models--Qwen--Qwen2.5-Omni-7B/snapshots/ae9e1690543ffd5c0221dc27f79834d0294cba00', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|AUDIO|>', '<|audio_bos|>', '<|audio_eos|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_bos|>', '<|vision_eos|>', '<|vision_pad|>', '<|IMAGE|>', '<|VIDEO|>'], 'image_token': '<|IMAGE|>', 'audio_token': '<|AUDIO|>', 'video_token': '<|VIDEO|>', 'vision_bos_token': '<|vision_bos|>', 'vision_eos_token': '<|vision_eos|>', 'audio_bos_token': '<|audio_bos|>', 'audio_eos_token': '<|audio_eos|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|AUDIO|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|audio_bos|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|audio_eos|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_bos|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_eos|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|IMAGE|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|VIDEO|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
}
)

{
  "processor_class": "Qwen2_5OmniProcessor"
}

[WARNING|2025-10-22 12:20:52] llamafactory.data.loader:148 >> Loading dataset from disk will ignore other data arguments.
[INFO|2025-10-22 12:20:52] llamafactory.data.loader:143 >> Loaded tokenized dataset from /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/saves/datasets/lemon_tok_192.
[INFO|configuration_utils.py:696] 2025-10-22 12:20:52,449 >> loading configuration file /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/hf_cache/models--Qwen--Qwen2.5-Omni-7B/snapshots/ae9e1690543ffd5c0221dc27f79834d0294cba00/config.json
[WARNING|modeling_rope_utils.py:467] 2025-10-22 12:20:52,451 >> Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}
[INFO|configuration_qwen2_5_omni.py:1031] 2025-10-22 12:20:52,454 >> thinker_config is None. Initializing thinker model with default values
[INFO|configuration_qwen2_5_omni.py:1035] 2025-10-22 12:20:52,454 >> talker_config is None. Initializing talker model with default values
[INFO|configuration_qwen2_5_omni.py:1039] 2025-10-22 12:20:52,454 >> token2wav_config is None. Initializing token2wav model with default values
[INFO|configuration_utils.py:770] 2025-10-22 12:20:52,459 >> Model config Qwen2_5OmniConfig {
  "architectures": [
    "Qwen2_5OmniForConditionalGeneration"
  ],
  "enable_audio_output": true,
  "enable_talker": true,
  "model_type": "qwen2_5_omni",
  "talker_config": {
    "_name_or_path": "Qwen2.5-Omni-7B/talker",
    "architectures": [
      "Qwen2OmniTalkerForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "audio_end_token_id": 151648,
    "audio_start_token_id": 151647,
    "audio_token_index": 151646,
    "embedding_size": 3584,
    "head_dim": 128,
    "hidden_act": "silu",
    "hidden_size": 896,
    "image_token_index": 151655,
    "init_std": 0.02,
    "initializer_range": 0.02,
    "intermediate_size": 18944,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_5_omni_talker",
    "num_attention_heads": 12,
    "num_hidden_layers": 24,
    "num_key_value_heads": 4,
    "position_id_per_seconds": 25,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "seconds_per_chunk": 0.4,
    "sliding_window": 32768,
    "spatial_merge_size": 2,
    "torch_dtype": "bfloat16",
    "tts_codec_end_token_id": 8294,
    "tts_codec_mask_token_id": 8296,
    "tts_codec_pad_token_id": 8292,
    "tts_codec_start_token_id": 8293,
    "tts_text_end_token_id": 151861,
    "tts_text_pad_token_id": 151859,
    "tts_text_start_token_id": 151860,
    "use_cache": true,
    "use_sliding_window": false,
    "video_token_index": 151656,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vocab_size": 8448
  },
  "thinker_config": {
    "_name_or_path": "Qwen2.5-Omni-7B/thinker",
    "architectures": [
      "Qwen2OmniNaViTThinkerForConditionalGeneration"
    ],
    "audio_config": {
      "_name_or_path": "",
      "activation_dropout": 0.0,
      "activation_function": "gelu",
      "add_cross_attention": false,
      "architectures": null,
      "attention_dropout": 0.0,
      "bad_words_ids": null,
      "begin_suppress_tokens": null,
      "bos_token_id": null,
      "chunk_size_feed_forward": 0,
      "cross_attention_hidden_size": null,
      "d_model": 1280,
      "decoder_start_token_id": null,
      "diversity_penalty": 0.0,
      "do_sample": false,
      "dropout": 0.0,
      "early_stopping": false,
      "encoder_attention_heads": 20,
      "encoder_ffn_dim": 5120,
      "encoder_layerdrop": 0.0,
      "encoder_layers": 32,
      "encoder_no_repeat_ngram_size": 0,
      "eos_token_id": null,
      "exponential_decay_length_penalty": null,
      "finetuning_task": null,
      "forced_bos_token_id": null,
      "forced_eos_token_id": null,
      "id2label": {
        "0": "LABEL_0",
        "1": "LABEL_1"
      },
      "init_std": 0.02,
      "initializer_range": 0.02,
      "is_decoder": false,
      "is_encoder_decoder": false,
      "label2id": {
        "LABEL_0": 0,
        "LABEL_1": 1
      },
      "length_penalty": 1.0,
      "max_length": 20,
      "max_source_positions": 1500,
      "min_length": 0,
      "model_type": "qwen2_5_omni_audio_encoder",
      "n_window": 100,
      "no_repeat_ngram_size": 0,
      "num_beam_groups": 1,
      "num_beams": 1,
      "num_hidden_layers": 32,
      "num_mel_bins": 128,
      "num_return_sequences": 1,
      "output_attentions": false,
      "output_dim": 3584,
      "output_hidden_states": false,
      "output_scores": false,
      "pad_token_id": null,
      "prefix": null,
      "problem_type": null,
      "pruned_heads": {},
      "remove_invalid_values": false,
      "repetition_penalty": 1.0,
      "return_dict": true,
      "return_dict_in_generate": false,
      "scale_embedding": false,
      "sep_token_id": null,
      "suppress_tokens": null,
      "task_specific_params": null,
      "temperature": 1.0,
      "tf_legacy_loss": false,
      "tie_encoder_decoder": false,
      "tie_word_embeddings": true,
      "tokenizer_class": null,
      "top_k": 50,
      "top_p": 1.0,
      "torch_dtype": null,
      "torchscript": false,
      "typical_p": 1.0,
      "use_bfloat16": false
    },
    "audio_end_token_id": 151648,
    "audio_start_token_id": 151647,
    "audio_token_index": 151646,
    "bos_token_id": 151644,
    "eos_token_id": 151645,
    "ignore_index": -100,
    "image_token_index": 151655,
    "init_std": 0.02,
    "initializer_range": 0.02,
    "model_type": "qwen2_5_omni_thinker",
    "pad_token_id": 151643,
    "position_id_per_seconds": 25,
    "seconds_per_chunk": 0.4,
    "text_config": {
      "_name_or_path": "",
      "add_cross_attention": false,
      "architectures": null,
      "attention_dropout": 0.0,
      "bad_words_ids": null,
      "begin_suppress_tokens": null,
      "bos_token_id": null,
      "chunk_size_feed_forward": 0,
      "cross_attention_hidden_size": null,
      "decoder_start_token_id": null,
      "diversity_penalty": 0.0,
      "do_sample": false,
      "early_stopping": false,
      "encoder_no_repeat_ngram_size": 0,
      "eos_token_id": null,
      "exponential_decay_length_penalty": null,
      "finetuning_task": null,
      "forced_bos_token_id": null,
      "forced_eos_token_id": null,
      "hidden_act": "silu",
      "hidden_size": 3584,
      "id2label": {
        "0": "LABEL_0",
        "1": "LABEL_1"
      },
      "init_std": 0.02,
      "initializer_range": 0.02,
      "intermediate_size": 18944,
      "is_decoder": false,
      "is_encoder_decoder": false,
      "label2id": {
        "LABEL_0": 0,
        "LABEL_1": 1
      },
      "length_penalty": 1.0,
      "max_length": 20,
      "max_position_embeddings": 32768,
      "max_window_layers": 28,
      "min_length": 0,
      "model_type": "qwen2_5_omni_text",
      "no_repeat_ngram_size": 0,
      "num_attention_heads": 28,
      "num_beam_groups": 1,
      "num_beams": 1,
      "num_hidden_layers": 28,
      "num_key_value_heads": 4,
      "num_return_sequences": 1,
      "output_attentions": false,
      "output_hidden_states": false,
      "output_scores": false,
      "pad_token_id": null,
      "prefix": null,
      "problem_type": null,
      "pruned_heads": {},
      "remove_invalid_values": false,
      "repetition_penalty": 1.0,
      "return_dict": true,
      "return_dict_in_generate": false,
      "rms_norm_eps": 1e-06,
      "rope_scaling": {
        "mrope_section": [
          16,
          24,
          24
        ],
        "rope_type": "default",
        "type": "default"
      },
      "rope_theta": 1000000.0,
      "sep_token_id": null,
      "sliding_window": 32768,
      "suppress_tokens": null,
      "task_specific_params": null,
      "temperature": 1.0,
      "tf_legacy_loss": false,
      "tie_encoder_decoder": false,
      "tie_word_embeddings": false,
      "tokenizer_class": null,
      "top_k": 50,
      "top_p": 1.0,
      "torch_dtype": null,
      "torchscript": false,
      "typical_p": 1.0,
      "use_bfloat16": false,
      "use_cache": true,
      "use_sliding_window": false,
      "vocab_size": 152064
    },
    "torch_dtype": "bfloat16",
    "user_token_id": 872,
    "video_token_index": 151656,
    "vision_config": {
      "_name_or_path": "",
      "add_cross_attention": false,
      "architectures": null,
      "bad_words_ids": null,
      "begin_suppress_tokens": null,
      "bos_token_id": null,
      "chunk_size_feed_forward": 0,
      "cross_attention_hidden_size": null,
      "decoder_start_token_id": null,
      "depth": 32,
      "diversity_penalty": 0.0,
      "do_sample": false,
      "early_stopping": false,
      "embed_dim": 1280,
      "encoder_no_repeat_ngram_size": 0,
      "eos_token_id": null,
      "exponential_decay_length_penalty": null,
      "finetuning_task": null,
      "forced_bos_token_id": null,
      "forced_eos_token_id": null,
      "fullatt_block_indexes": [
        7,
        15,
        23,
        31
      ],
      "hidden_act": "silu",
      "hidden_size": 1280,
      "id2label": {
        "0": "LABEL_0",
        "1": "LABEL_1"
      },
      "in_channels": 3,
      "in_chans": 3,
      "init_std": 0.02,
      "initializer_range": 0.02,
      "intermediate_size": 3420,
      "is_decoder": false,
      "is_encoder_decoder": false,
      "label2id": {
        "LABEL_0": 0,
        "LABEL_1": 1
      },
      "length_penalty": 1.0,
      "max_length": 20,
      "min_length": 0,
      "model_type": "qwen2_5_omni_vision_encoder",
      "no_repeat_ngram_size": 0,
      "num_beam_groups": 1,
      "num_beams": 1,
      "num_heads": 16,
      "num_return_sequences": 1,
      "out_hidden_size": 3584,
      "output_attentions": false,
      "output_hidden_states": false,
      "output_scores": false,
      "pad_token_id": null,
      "patch_size": 14,
      "prefix": null,
      "problem_type": null,
      "pruned_heads": {},
      "remove_invalid_values": false,
      "repetition_penalty": 1.0,
      "return_dict": true,
      "return_dict_in_generate": false,
      "sep_token_id": null,
      "spatial_merge_size": 2,
      "spatial_patch_size": 14,
      "suppress_tokens": null,
      "task_specific_params": null,
      "temperature": 1.0,
      "temporal_patch_size": 2,
      "tf_legacy_loss": false,
      "tie_encoder_decoder": false,
      "tie_word_embeddings": true,
      "tokenizer_class": null,
      "tokens_per_second": 25,
      "top_k": 50,
      "top_p": 1.0,
      "torch_dtype": null,
      "torchscript": false,
      "typical_p": 1.0,
      "use_bfloat16": false,
      "window_size": 112
    },
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654
  },
  "token2wav_config": {
    "bigvgan_config": {
      "_name_or_path": "",
      "add_cross_attention": false,
      "architectures": null,
      "bad_words_ids": null,
      "begin_suppress_tokens": null,
      "bos_token_id": null,
      "chunk_size_feed_forward": 0,
      "cross_attention_hidden_size": null,
      "decoder_start_token_id": null,
      "diversity_penalty": 0.0,
      "do_sample": false,
      "early_stopping": false,
      "encoder_no_repeat_ngram_size": 0,
      "eos_token_id": null,
      "exponential_decay_length_penalty": null,
      "finetuning_task": null,
      "forced_bos_token_id": null,
      "forced_eos_token_id": null,
      "id2label": {
        "0": "LABEL_0",
        "1": "LABEL_1"
      },
      "is_decoder": false,
      "is_encoder_decoder": false,
      "label2id": {
        "LABEL_0": 0,
        "LABEL_1": 1
      },
      "length_penalty": 1.0,
      "max_length": 20,
      "mel_dim": 80,
      "min_length": 0,
      "model_type": "qwen2_5_omni_bigvgan",
      "no_repeat_ngram_size": 0,
      "num_beam_groups": 1,
      "num_beams": 1,
      "num_return_sequences": 1,
      "output_attentions": false,
      "output_hidden_states": false,
      "output_scores": false,
      "pad_token_id": null,
      "prefix": null,
      "problem_type": null,
      "pruned_heads": {},
      "remove_invalid_values": false,
      "repetition_penalty": 1.0,
      "resblock_dilation_sizes": [
        [
          1,
          3,
          5
        ],
        [
          1,
          3,
          5
        ],
        [
          1,
          3,
          5
        ]
      ],
      "resblock_kernel_sizes": [
        3,
        7,
        11
      ],
      "return_dict": true,
      "return_dict_in_generate": false,
      "sep_token_id": null,
      "suppress_tokens": null,
      "task_specific_params": null,
      "temperature": 1.0,
      "tf_legacy_loss": false,
      "tie_encoder_decoder": false,
      "tie_word_embeddings": true,
      "tokenizer_class": null,
      "top_k": 50,
      "top_p": 1.0,
      "torch_dtype": null,
      "torchscript": false,
      "typical_p": 1.0,
      "upsample_initial_channel": 1536,
      "upsample_kernel_sizes": [
        11,
        7,
        4,
        4,
        4,
        4
      ],
      "upsample_rates": [
        5,
        3,
        2,
        2,
        2,
        2
      ],
      "use_bfloat16": false,
      "use_bias_at_final": false
    },
    "dit_config": {
      "_name_or_path": "",
      "add_cross_attention": false,
      "architectures": null,
      "bad_words_ids": null,
      "begin_suppress_tokens": null,
      "block_size": 24,
      "bos_token_id": null,
      "chunk_size_feed_forward": 0,
      "cross_attention_hidden_size": null,
      "decoder_start_token_id": null,
      "depth": 22,
      "dim": 1024,
      "diversity_penalty": 0.0,
      "do_sample": false,
      "dropout": 0.1,
      "early_stopping": false,
      "emb_dim": 512,
      "enc_attention_channels": 64,
      "enc_channels": [
        256,
        256,
        256,
        256,
        768
      ],
      "enc_dilations": [
        1,
        2,
        3,
        4,
        1
      ],
      "enc_dim": 128,
      "enc_emb_dim": 192,
      "enc_global_context": true,
      "enc_kernel_sizes": [
        5,
        3,
        3,
        3,
        1
      ],
      "enc_lin_neurons": 192,
      "enc_res2net_scale": 2,
      "enc_se_channels": 64,
      "encoder_no_repeat_ngram_size": 0,
      "eos_token_id": null,
      "exponential_decay_length_penalty": null,
      "ff_mult": 2,
      "finetuning_task": null,
      "forced_bos_token_id": null,
      "forced_eos_token_id": null,
      "head_dim": 64,
      "heads": 16,
      "hidden_size": 1024,
      "id2label": {
        "0": "LABEL_0",
        "1": "LABEL_1"
      },
      "is_decoder": false,
      "is_encoder_decoder": false,
      "label2id": {
        "LABEL_0": 0,
        "LABEL_1": 1
      },
      "length_penalty": 1.0,
      "look_ahead_layers": [
        10
      ],
      "look_backward_layers": [
        0,
        20
      ],
      "max_length": 20,
      "max_position_embeddings": 32768,
      "mel_dim": 80,
      "min_length": 0,
      "model_type": "qwen2_5_omni_dit",
      "no_repeat_ngram_size": 0,
      "num_attention_heads": 16,
      "num_beam_groups": 1,
      "num_beams": 1,
      "num_embeds": 8193,
      "num_hidden_layers": 22,
      "num_return_sequences": 1,
      "output_attentions": false,
      "output_hidden_states": false,
      "output_scores": false,
      "pad_token_id": null,
      "prefix": null,
      "problem_type": null,
      "pruned_heads": {},
      "remove_invalid_values": false,
      "repeats": 2,
      "repetition_penalty": 1.0,
      "return_dict": true,
      "return_dict_in_generate": false,
      "rope_theta": 10000.0,
      "sep_token_id": null,
      "suppress_tokens": null,
      "task_specific_params": null,
      "temperature": 1.0,
      "tf_legacy_loss": false,
      "tie_encoder_decoder": false,
      "tie_word_embeddings": true,
      "tokenizer_class": null,
      "top_k": 50,
      "top_p": 1.0,
      "torch_dtype": "float32",
      "torchscript": false,
      "typical_p": 1.0,
      "use_bfloat16": false
    },
    "model_type": "qwen2_5_omni_token2wav"
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.2"
}

[INFO|2025-10-22 12:20:52] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
Qwen2_5OmniToken2WavModel does not support eager attention implementation, fall back to sdpa
Qwen2_5OmniToken2WavModel does not support eager attention implementation, fall back to sdpa
[INFO|modeling_utils.py:1147] 2025-10-22 12:20:52,620 >> loading weights file /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/hf_cache/models--Qwen--Qwen2.5-Omni-7B/snapshots/ae9e1690543ffd5c0221dc27f79834d0294cba00/model.safetensors.index.json
[INFO|modeling_utils.py:2240] 2025-10-22 12:20:52,621 >> Instantiating Qwen2_5OmniForConditionalGeneration model under default dtype torch.bfloat16.
[INFO|configuration_utils.py:1135] 2025-10-22 12:20:52,627 >> Generate config GenerationConfig {
  "use_cache": false
}

[INFO|configuration_utils.py:1135] 2025-10-22 12:20:52,628 >> Generate config GenerationConfig {
  "bos_token_id": 151644,
  "eos_token_id": 151645,
  "pad_token_id": 151643
}

[INFO|configuration_utils.py:1135] 2025-10-22 12:20:52,686 >> Generate config GenerationConfig {}

[WARNING|logging.py:328] 2025-10-22 12:20:52,701 >> Qwen2_5OmniToken2WavModel does not support eager attention implementation, fall back to sdpa
[INFO|modeling_utils.py:2240] 2025-10-22 12:20:52,701 >> Instantiating Qwen2_5OmniToken2WavDiTModel model under default dtype torch.float32.
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Qwen2_5OmniToken2WavModel does not support eager attention implementation, fall back to sdpa
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:01<00:06,  1.75s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:01<00:06,  1.74s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:01<00:05,  1.36s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:01<00:06,  1.75s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:02<00:03,  1.05s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:02<00:03,  1.19s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:02<00:03,  1.31s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:02<00:03,  1.31s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:03<00:01,  1.05it/s]Loading checkpoint shards:  60%|██████    | 3/5 [00:03<00:02,  1.02s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:03<00:02,  1.17s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:03<00:02,  1.17s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:04<00:00,  1.01it/s]Loading checkpoint shards:  80%|████████  | 4/5 [00:04<00:00,  1.04it/s]Loading checkpoint shards:  80%|████████  | 4/5 [00:04<00:01,  1.14s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:04<00:01,  1.14s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:04<00:00,  1.12it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:04<00:00,  1.05it/s]
Loading checkpoint shards: 100%|██████████| 5/5 [00:05<00:00,  1.10it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:05<00:00,  1.01s/it]
[INFO|modeling_utils.py:5130] 2025-10-22 12:20:57,968 >> All model checkpoint weights were used when initializing Qwen2_5OmniForConditionalGeneration.

[INFO|modeling_utils.py:5138] 2025-10-22 12:20:57,969 >> All the weights of Qwen2_5OmniForConditionalGeneration were initialized from the model checkpoint at /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/hf_cache/models--Qwen--Qwen2.5-Omni-7B/snapshots/ae9e1690543ffd5c0221dc27f79834d0294cba00.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2_5OmniForConditionalGeneration for predictions without further training.
[INFO|configuration_utils.py:1088] 2025-10-22 12:20:57,980 >> loading configuration file /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/hf_cache/models--Qwen--Qwen2.5-Omni-7B/snapshots/ae9e1690543ffd5c0221dc27f79834d0294cba00/generation_config.json
[INFO|configuration_utils.py:1135] 2025-10-22 12:20:57,981 >> Generate config GenerationConfig {}

[INFO|modeling_qwen2_5_omni.py:4767] 2025-10-22 12:20:58,020 >> Speaker ['Ethan', 'Chelsie'] loaded
[INFO|2025-10-22 12:20:58] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
[INFO|2025-10-22 12:20:58] llamafactory.model.model_utils.attention:143 >> Using vanilla attention implementation.
[INFO|2025-10-22 12:20:58] llamafactory.model.adapter:143 >> Upcasting trainable params to float32.
[INFO|2025-10-22 12:20:58] llamafactory.model.adapter:143 >> Fine-tuning method: LoRA
[INFO|2025-10-22 12:20:58] llamafactory.model.model_utils.misc:143 >> Found linear modules: q_proj,up_proj,gate_proj,k_proj,v_proj,o_proj,down_proj
[INFO|2025-10-22 12:20:58] llamafactory.model.model_utils.visual:143 >> Set vision model not trainable: ['visual.patch_embed', 'visual.blocks', 'audio_tower'].
[INFO|2025-10-22 12:20:58] llamafactory.model.model_utils.visual:143 >> Set multi model projector not trainable: visual.merger.
Loading checkpoint shards: 100%|██████████| 5/5 [00:05<00:00,  1.02s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:05<00:00,  1.02s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:05<00:00,  1.13s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:05<00:00,  1.13s/it]
[INFO|2025-10-22 12:20:58] llamafactory.model.loader:143 >> trainable params: 40,370,176 || all params: 8,972,184,064 || trainable%: 0.4499
name: base_model.model.audio_tower.conv1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.conv1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.conv2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.conv2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.audio_bos_eos_token.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.0.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.0.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.0.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.0.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.0.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.0.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.0.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.0.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.0.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.0.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.0.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.0.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.0.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.0.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.0.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.1.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.1.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.1.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.1.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.1.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.1.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.1.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.1.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.1.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.1.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.1.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.1.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.1.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.1.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.1.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.2.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.2.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.2.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.2.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.2.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.2.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.2.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.2.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.2.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.2.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.2.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.2.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.2.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.2.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.2.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.3.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.3.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.3.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.3.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.3.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.3.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.3.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.3.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.3.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.3.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.3.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.3.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.3.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.3.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.3.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.4.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.4.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.4.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.4.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.4.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.4.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.4.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.4.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.4.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.4.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.4.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.4.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.4.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.4.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.4.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.5.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.5.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.5.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.5.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.5.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.5.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.5.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.5.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.5.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.5.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.5.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.5.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.5.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.5.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.5.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.6.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.6.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.6.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.6.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.6.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.6.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.6.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.6.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.6.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.6.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.6.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.6.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.6.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.6.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.6.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.7.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.7.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.7.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.7.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.7.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.7.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.7.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.7.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.7.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.7.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.7.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.7.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.7.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.7.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.7.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.8.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.8.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.8.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.8.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.8.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.8.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.8.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.8.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.8.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.8.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.8.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.8.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.8.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.8.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.8.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.9.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.9.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.9.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.9.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.9.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.9.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.9.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.9.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.9.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.9.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.9.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.9.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.9.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.9.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.9.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.10.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.10.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.10.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.10.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.10.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.10.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.10.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.10.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.10.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.10.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.10.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.10.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.10.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.10.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.10.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.11.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.11.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.11.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.11.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.11.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.11.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.11.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.11.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.11.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.11.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.11.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.11.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.11.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.11.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.11.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.12.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.12.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.12.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.12.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.12.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.12.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.12.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.12.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.12.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.12.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.12.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.12.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.12.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.12.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.12.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.13.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.13.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.13.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.13.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.13.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.13.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.13.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.13.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.13.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.13.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.13.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.13.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.13.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.13.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.13.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.14.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.14.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.14.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.14.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.14.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.14.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.14.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.14.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.14.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.14.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.14.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.14.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.14.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.14.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.14.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.15.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.15.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.15.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.15.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.15.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.15.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.15.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.15.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.15.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.15.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.15.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.15.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.15.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.15.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.15.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.16.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.16.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.16.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.16.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.16.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.16.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.16.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.16.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.16.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.16.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.16.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.16.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.16.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.16.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.16.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.17.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.17.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.17.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.17.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.17.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.17.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.17.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.17.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.17.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.17.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.17.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.17.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.17.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.17.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.17.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.18.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.18.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.18.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.18.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.18.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.18.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.18.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.18.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.18.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.18.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.18.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.18.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.18.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.18.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.18.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.19.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.19.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.19.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.19.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.19.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.19.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.19.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.19.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.19.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.19.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.19.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.19.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.19.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.19.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.19.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.20.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.20.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.20.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.20.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.20.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.20.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.20.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.20.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.20.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.20.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.20.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.20.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.20.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.20.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.20.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.21.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.21.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.21.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.21.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.21.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.21.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.21.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.21.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.21.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.21.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.21.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.21.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.21.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.21.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.21.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.22.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.22.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.22.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.22.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.22.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.22.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.22.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.22.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.22.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.22.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.22.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.22.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.22.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.22.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.22.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.23.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.23.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.23.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.23.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.23.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.23.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.23.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.23.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.23.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.23.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.23.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.23.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.23.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.23.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.23.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.24.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.24.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.24.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.24.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.24.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.24.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.24.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.24.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.24.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.24.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.24.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.24.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.24.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.24.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.24.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.25.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.25.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.25.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.25.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.25.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.25.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.25.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.25.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.25.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.25.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.25.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.25.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.25.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.25.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.25.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.26.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.26.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.26.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.26.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.26.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.26.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.26.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.26.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.26.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.26.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.26.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.26.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.26.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.26.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.26.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.27.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.27.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.27.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.27.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.27.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.27.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.27.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.27.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.27.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.27.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.27.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.27.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.27.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.27.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.27.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.28.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.28.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.28.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.28.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.28.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.28.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.28.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.28.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.28.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.28.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.28.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.28.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.28.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.28.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.28.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.29.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.29.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.29.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.29.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.29.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.29.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.29.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.29.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.29.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.29.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.29.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.29.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.29.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.29.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.29.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.30.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.30.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.30.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.30.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.30.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.30.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.30.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.30.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.30.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.30.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.30.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.30.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.30.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.30.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.30.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.31.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.31.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.31.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.31.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.31.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.31.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.31.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.31.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.31.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.31.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.31.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.31.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.31.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.31.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.31.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.ln_post.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.ln_post.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.patch_embed.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.0.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.0.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.0.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.0.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.0.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.0.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.0.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.0.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.0.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.0.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.0.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.0.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.0.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.0.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.0.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.0.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.1.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.1.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.1.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.1.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.1.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.1.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.1.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.1.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.1.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.1.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.1.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.1.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.1.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.1.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.1.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.1.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.2.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.2.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.2.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.2.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.2.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.2.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.2.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.2.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.2.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.2.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.2.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.2.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.2.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.2.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.2.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.2.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.3.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.3.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.3.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.3.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.3.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.3.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.3.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.3.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.3.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.3.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.3.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.3.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.3.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.3.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.3.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.3.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.4.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.4.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.4.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.4.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.4.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.4.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.4.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.4.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.4.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.4.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.4.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.4.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.4.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.4.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.4.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.4.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.5.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.5.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.5.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.5.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.5.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.5.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.5.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.5.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.5.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.5.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.5.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.5.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.5.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.5.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.5.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.5.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.6.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.6.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.6.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.6.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.6.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.6.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.6.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.6.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.6.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.6.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.6.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.6.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.6.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.6.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.6.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.6.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.7.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.7.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.7.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.7.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.7.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.7.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.7.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.7.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.7.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.7.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.7.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.7.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.7.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.7.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.7.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.7.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.8.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.8.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.8.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.8.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.8.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.8.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.8.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.8.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.8.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.8.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.8.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.8.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.8.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.8.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.8.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.8.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.9.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.9.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.9.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.9.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.9.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.9.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.9.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.9.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.9.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.9.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.9.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.9.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.9.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.9.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.9.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.9.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.10.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.10.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.10.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.10.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.10.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.10.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.10.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.10.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.10.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.10.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.10.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.10.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.10.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.10.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.10.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.10.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.11.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.11.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.11.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.11.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.11.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.11.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.11.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.11.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.11.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.11.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.11.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.11.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.11.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.11.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.11.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.11.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.12.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.12.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.12.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.12.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.12.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.12.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.12.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.12.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.12.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.12.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.12.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.12.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.12.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.12.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.12.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.12.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.13.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.13.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.13.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.13.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.13.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.13.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.13.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.13.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.13.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.13.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.13.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.13.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.13.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.13.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.13.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.13.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.14.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.14.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.14.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.14.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.14.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.14.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.14.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.14.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.14.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.14.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.14.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.14.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.14.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.14.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.14.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.14.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.15.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.15.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.15.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.15.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.15.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.15.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.15.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.15.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.15.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.15.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.15.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.15.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.15.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.15.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.15.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.15.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.16.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.16.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.16.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.16.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.16.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.16.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.16.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.16.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.16.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.16.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.16.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.16.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.16.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.16.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.16.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.16.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.17.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.17.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.17.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.17.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.17.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.17.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.17.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.17.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.17.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.17.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.17.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.17.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.17.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.17.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.17.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.17.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.18.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.18.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.18.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.18.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.18.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.18.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.18.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.18.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.18.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.18.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.18.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.18.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.18.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.18.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.18.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.18.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.19.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.19.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.19.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.19.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.19.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.19.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.19.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.19.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.19.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.19.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.19.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.19.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.19.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.19.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.19.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.19.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.20.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.20.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.20.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.20.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.20.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.20.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.20.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.20.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.20.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.20.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.20.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.20.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.20.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.20.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.20.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.20.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.21.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.21.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.21.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.21.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.21.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.21.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.21.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.21.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.21.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.21.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.21.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.21.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.21.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.21.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.21.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.21.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.22.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.22.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.22.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.22.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.22.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.22.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.22.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.22.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.22.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.22.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.22.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.22.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.22.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.22.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.22.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.22.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.23.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.23.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.23.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.23.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.23.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.23.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.23.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.23.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.23.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.23.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.23.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.23.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.23.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.23.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.23.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.23.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.24.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.24.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.24.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.24.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.24.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.24.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.24.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.24.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.24.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.24.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.24.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.24.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.24.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.24.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.24.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.24.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.25.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.25.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.25.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.25.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.25.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.25.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.25.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.25.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.25.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.25.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.25.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.25.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.25.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.25.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.25.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.25.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.26.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.26.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.26.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.26.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.26.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.26.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.26.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.26.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.26.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.26.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.26.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.26.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.26.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.26.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.26.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.26.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.27.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.27.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.27.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.27.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.27.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.27.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.27.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.27.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.27.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.27.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.27.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.27.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.27.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.27.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.27.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.27.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.28.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.28.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.28.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.28.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.28.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.28.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.28.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.28.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.28.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.28.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.28.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.28.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.28.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.28.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.28.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.28.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.29.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.29.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.29.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.29.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.29.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.29.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.29.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.29.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.29.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.29.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.29.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.29.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.29.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.29.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.29.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.29.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.30.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.30.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.30.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.30.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.30.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.30.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.30.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.30.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.30.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.30.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.30.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.30.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.30.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.30.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.30.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.30.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.31.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.31.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.31.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.31.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.31.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.31.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.31.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.31.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.31.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.31.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.31.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.31.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.31.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.31.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.31.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.31.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.merger.ln_q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.merger.mlp.0.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.merger.mlp.0.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.merger.mlp.2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.merger.mlp.2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.embed_tokens.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.0.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.0.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.0.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.0.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.0.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.0.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.0.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.0.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.1.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.1.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.1.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.1.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.1.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.1.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.1.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.1.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.2.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.2.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.2.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.2.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.2.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.2.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.2.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.2.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.3.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.3.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.3.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.3.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.3.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.3.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.3.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.3.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.4.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.4.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.4.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.4.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.4.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.4.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.4.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.4.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.5.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.5.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.5.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.5.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.5.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.5.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.5.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.5.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.6.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.6.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.6.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.6.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.6.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.6.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.6.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.6.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.7.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.7.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.7.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.7.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.7.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.7.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.7.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.7.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.8.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.8.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.8.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.8.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.8.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.8.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.8.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.8.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.9.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.9.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.9.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.9.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.9.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.9.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.9.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.9.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.10.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.10.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.10.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.10.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.10.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.10.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.10.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.10.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.11.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.11.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.11.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.11.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.11.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.11.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.11.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.11.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.12.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.12.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.12.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.12.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.12.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.12.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.12.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.12.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.13.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.13.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.13.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.13.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.13.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.13.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.13.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.13.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.14.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.14.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.14.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.14.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.14.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.14.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.14.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.14.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.15.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.15.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.15.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.15.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.15.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.15.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.15.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.15.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.16.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.16.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.16.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.16.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.16.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.16.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.16.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.16.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.16.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.16.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.17.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.17.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.17.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.17.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.17.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.17.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.17.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.17.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.17.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.17.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.18.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.18.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.18.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.18.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.18.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.18.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.18.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.18.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.18.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.18.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.19.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.19.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.19.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.19.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.19.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.19.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.19.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.19.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.19.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.19.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.20.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.20.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.20.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.20.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.20.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.20.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.20.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.20.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.20.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.20.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.21.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.21.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.21.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.21.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.21.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.21.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.21.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.21.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.21.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.21.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.22.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.22.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.22.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.22.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.22.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.22.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.22.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.22.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.22.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.22.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.23.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.23.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.23.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.23.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.23.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.23.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.23.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.23.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.23.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.23.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.24.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.24.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.24.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.24.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.24.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.24.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.24.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.24.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.24.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.24.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.24.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.24.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.24.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.24.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.25.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.25.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.25.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.25.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.25.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.25.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.25.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.25.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.25.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.25.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.25.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.25.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.25.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.25.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.26.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.26.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.26.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.26.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.26.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.26.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.26.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.26.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.26.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.26.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.26.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.26.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.26.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.26.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.27.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.27.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.27.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.27.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.27.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.27.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.27.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.27.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.27.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.27.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.27.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.27.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.27.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.27.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.lm_head.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
[INFO|trainer.py:706] 2025-10-22 12:20:58,690 >> max_steps is given, it will override any value given in num_train_epochs
[INFO|trainer.py:756] 2025-10-22 12:20:58,691 >> Using auto half precision backend
Gradient accumulation steps mismatch: GradientAccumulationPlugin has 1, DeepSpeed config has 8. Using DeepSpeed's value.
[2025-10-22 12:20:59,083] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed info: version=0.17.4, git-hash=unknown, git-branch=unknown
[2025-10-22 12:20:59,084] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 4
[2025-10-22 12:20:59,129] [INFO] [engine.py:1339:_configure_distributed_model] ********** distributed groups summary **********
	 self.dp_world_size=4
	 self.mp_world_size=1
	 self.seq_dp_world_size=4
	 self.sequence_parallel_size=1
***********************************************
[2025-10-22 12:20:59,944] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2025-10-22 12:20:59,947] [INFO] [logging.py:107:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2025-10-22 12:20:59,947] [INFO] [logging.py:107:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2025-10-22 12:20:59,983] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2025-10-22 12:20:59,983] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>
[2025-10-22 12:20:59,984] [INFO] [logging.py:107:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2025-10-22 12:20:59,984] [INFO] [stage_1_and_2.py:172:__init__] Reduce bucket size 500000000
[2025-10-22 12:20:59,984] [INFO] [stage_1_and_2.py:173:__init__] Allgather bucket size 500000000
[2025-10-22 12:20:59,984] [INFO] [stage_1_and_2.py:174:__init__] CPU Offload: False
[2025-10-22 12:20:59,984] [INFO] [stage_1_and_2.py:175:__init__] Round robin gradient partitioning: False
[2025-10-22 12:21:01,003] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states
[2025-10-22 12:21:01,003] [INFO] [utils.py:782:see_memory_usage] MA 16.75 GB         Max_MA 16.77 GB         CA 16.81 GB         Max_CA 17 GB 
[2025-10-22 12:21:01,004] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 41.49 GB, percent = 8.2%
[2025-10-22 12:21:01,277] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states
[2025-10-22 12:21:01,278] [INFO] [utils.py:782:see_memory_usage] MA 16.75 GB         Max_MA 16.79 GB         CA 16.85 GB         Max_CA 17 GB 
[2025-10-22 12:21:01,281] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 41.68 GB, percent = 8.3%
[2025-10-22 12:21:01,281] [INFO] [stage_1_and_2.py:599:__init__] optimizer state initialized
[2025-10-22 12:21:01,533] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer
[2025-10-22 12:21:01,533] [INFO] [utils.py:782:see_memory_usage] MA 16.75 GB         Max_MA 16.75 GB         CA 16.85 GB         Max_CA 17 GB 
[2025-10-22 12:21:01,534] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 41.78 GB, percent = 8.3%
[2025-10-22 12:21:01,536] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer
[2025-10-22 12:21:01,537] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = None
[2025-10-22 12:21:01,537] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2025-10-22 12:21:01,537] [INFO] [logging.py:107:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0], mom=[(0.9, 0.999)]
[2025-10-22 12:21:01,541] [INFO] [logging.py:107:log_dist] [Rank 0] [TorchCheckpointEngine] Initialized with serialization = True
[2025-10-22 12:21:01,541] [INFO] [config.py:954:print] DeepSpeedEngine configuration:
[2025-10-22 12:21:01,542] [INFO] [config.py:958:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-10-22 12:21:01,542] [INFO] [config.py:958:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'intra_op_parallelism': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[2025-10-22 12:21:01,542] [INFO] [config.py:958:print]   amp_enabled .................. False
[2025-10-22 12:21:01,542] [INFO] [config.py:958:print]   amp_params ................... False
[2025-10-22 12:21:01,542] [INFO] [config.py:958:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-10-22 12:21:01,542] [INFO] [config.py:958:print]   bfloat16_config .............. enabled=True immediate_grad_update=False check_grad_overflow=False
[2025-10-22 12:21:01,542] [INFO] [config.py:958:print]   checkpoint_config ............ {'tag_validation': 'WARN', 'checkpoint_serialization': True, 'writer': None}
[2025-10-22 12:21:01,542] [INFO] [config.py:958:print]   checkpoint_parallel_write_pipeline  False
[2025-10-22 12:21:01,542] [INFO] [config.py:958:print]   checkpoint_tag_validation_enabled  True
[2025-10-22 12:21:01,542] [INFO] [config.py:958:print]   checkpoint_tag_validation_fail  False
[2025-10-22 12:21:01,542] [INFO] [config.py:958:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fdc96221970>
[2025-10-22 12:21:01,542] [INFO] [config.py:958:print]   communication_data_type ...... None
[2025-10-22 12:21:01,542] [INFO] [config.py:958:print]   compile_config ............... deepcompile=False free_activation=False offload_activation=False offload_opt_states=False double_buffer=True symmetric_memory=False debug_log=False offload_parameters=False sync_before_reduce=False sync_after_reduce=False sync_before_allgather=False sync_after_allgather=False keep_int_input_tensors=True keep_all_input_tensors=False
[2025-10-22 12:21:01,542] [INFO] [config.py:958:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-10-22 12:21:01,542] [INFO] [config.py:958:print]   curriculum_enabled_legacy .... False
[2025-10-22 12:21:01,542] [INFO] [config.py:958:print]   curriculum_params_legacy ..... False
[2025-10-22 12:21:01,542] [INFO] [config.py:958:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'pin_memory': False, 'curriculum_learning': {'enabled': False}, 'dynamic_batching': {'enabled': False, 'lr_scaling_method': 'linear', 'min_batch_size': 1, 'max_batch_size': None, 'sequence_picking_order': 'dataloader', 'verbose': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-10-22 12:21:01,542] [INFO] [config.py:958:print]   data_efficiency_enabled ...... False
[2025-10-22 12:21:01,542] [INFO] [config.py:958:print]   dataloader_drop_last ......... False
[2025-10-22 12:21:01,542] [INFO] [config.py:958:print]   disable_allgather ............ False
[2025-10-22 12:21:01,542] [INFO] [config.py:958:print]   dump_state ................... False
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   eigenvalue_enabled ........... False
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   eigenvalue_gas_boundary_resolution  1
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   eigenvalue_layer_num ......... 0
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   eigenvalue_max_iter .......... 100
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   eigenvalue_stability ......... 1e-06
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   eigenvalue_tol ............... 0.01
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   eigenvalue_verbose ........... False
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   elasticity_enabled ........... False
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   float16_config ............... enabled=False auto_cast=False loss_scale=0.0 initial_scale_power=16 loss_scale_window=1000 hysteresis=2 consecutive_hysteresis=False min_loss_scale=1 fp16_master_weights_and_grads=False
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   global_rank .................. 0
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   grad_accum_dtype ............. None
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   gradient_accumulation_steps .. 8
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   gradient_clipping ............ 1.0
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   gradient_predivide_factor .... 1.0
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   graph_harvesting ............. False
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   load_universal_checkpoint .... False
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   memory_breakdown ............. False
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   mics_hierarchial_params_gather  False
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   mics_shard_size .............. -1
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   optimizer_legacy_fusion ...... False
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   optimizer_name ............... None
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   optimizer_params ............. None
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   pld_enabled .................. False
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   pld_params ................... False
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   prescale_gradients ........... False
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   scheduler_name ............... None
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   scheduler_params ............. None
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   seq_parallel_communication_data_type  torch.float32
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   sparse_attention ............. None
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   sparse_gradients_enabled ..... False
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   steps_per_print .............. inf
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   tensor_parallel_config ....... dtype=torch.float16 autotp_size=0 tp_overlap_comm=False tensor_parallel=TPConfig(tp_size=1, tp_grain_size=1, mpu=None, tp_group=None) injection_policy_tuple=None keep_module_on_host=False replace_with_kernel_inject=False
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   timers_config ................ enabled=True synchronized=True
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   torch_autocast_dtype ......... None
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   torch_autocast_enabled ....... False
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   torch_autocast_lower_precision_safe_modules  None
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   train_batch_size ............. 32
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   train_micro_batch_size_per_gpu  1
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   use_data_before_expert_parallel_  False
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   use_node_local_storage ....... False
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   wall_clock_breakdown ......... False
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   weight_quantization_config ... None
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   world_size ................... 4
[2025-10-22 12:21:01,543] [INFO] [config.py:958:print]   zero_allow_untested_optimizer  True
[2025-10-22 12:21:01,544] [INFO] [config.py:958:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=500000000 param_persistence_threshold=1000000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False zeropp_loco_param=None mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True log_trace_cache_warnings=False
[2025-10-22 12:21:01,544] [INFO] [config.py:958:print]   zero_enabled ................. True
[2025-10-22 12:21:01,544] [INFO] [config.py:958:print]   zero_force_ds_cpu_optimizer .. True
[2025-10-22 12:21:01,544] [INFO] [config.py:958:print]   zero_optimization_stage ...... 2
[2025-10-22 12:21:01,544] [INFO] [config.py:944:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 8, 
    "zero_optimization": {
        "stage": 2, 
        "overlap_comm": true, 
        "contiguous_gradients": true, 
        "reduce_bucket_size": 5.000000e+08, 
        "stage3_prefetch_bucket_size": 5.000000e+08, 
        "stage3_param_persistence_threshold": 1.000000e+06, 
        "gather_16bit_weights_on_model_save": false
    }, 
    "bf16": {
        "enabled": true
    }, 
    "fp16": {
        "enabled": false
    }, 
    "gradient_clipping": 1.0, 
    "wall_clock_breakdown": false, 
    "aio": {
        "block_size": 1.048576e+06, 
        "queue_depth": 8, 
        "single_submit": false, 
        "overlap_events": true
    }, 
    "steps_per_print": inf, 
    "zero_allow_untested_optimizer": true
}
[INFO|trainer.py:2409] 2025-10-22 12:21:01,545 >> ***** Running training *****
[INFO|trainer.py:2410] 2025-10-22 12:21:01,545 >>   Num examples = 1,206
[INFO|trainer.py:2411] 2025-10-22 12:21:01,545 >>   Num Epochs = 6
[INFO|trainer.py:2412] 2025-10-22 12:21:01,545 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:2415] 2025-10-22 12:21:01,545 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:2416] 2025-10-22 12:21:01,545 >>   Gradient Accumulation steps = 8
[INFO|trainer.py:2417] 2025-10-22 12:21:01,545 >>   Total optimization steps = 200
[INFO|trainer.py:2418] 2025-10-22 12:21:01,550 >>   Number of trainable parameters = 40,370,176
[INFO|integration_utils.py:832] 2025-10-22 12:21:01,554 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
wandb: Network error (SSLError), entering retry loop.
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Network error (SSLError), entering retry loop.
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
wandb: setting up run pelsgz4s
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/LLaMA-Factory/wandb/run-20251022_122111-pelsgz4s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora
wandb: ⭐️ View project at https://wandb.ai/zhuozhi1997-ucl/llamafactory
wandb: 🚀 View run at https://wandb.ai/zhuozhi1997-ucl/llamafactory/runs/pelsgz4s
  0%|          | 0/200 [00:00<?, ?it/s]mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
mother fucker!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
