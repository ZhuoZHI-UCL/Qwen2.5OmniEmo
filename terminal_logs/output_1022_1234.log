[INFO|2025-10-22 12:34:18] llamafactory.cli:143 >> Initializing 4 distributed tasks at: 127.0.0.1:35455
W1022 12:34:20.603000 3104052 site-packages/torch/distributed/run.py:766] 
W1022 12:34:20.603000 3104052 site-packages/torch/distributed/run.py:766] *****************************************
W1022 12:34:20.603000 3104052 site-packages/torch/distributed/run.py:766] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1022 12:34:20.603000 3104052 site-packages/torch/distributed/run.py:766] *****************************************
[2025-10-22 12:34:25,850] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-10-22 12:34:26,048] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[WARNING|2025-10-22 12:34:26] llamafactory.extras.misc:154 >> Version checking has been disabled, may lead to unexpected behaviors.
[2025-10-22 12:34:26,719] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-10-22 12:34:26,799] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-10-22 12:34:27,162] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-10-22 12:34:27,460] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-10-22 12:34:28,118] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-10-22 12:34:28,296] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-10-22 12:34:28,366] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-10-22 12:34:28,641] [INFO] [comm.py:821:init_distributed] cdb=None
[INFO|2025-10-22 12:34:28] llamafactory.hparams.parser:423 >> Process rank: 1, world size: 4, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16
You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.
[INFO|2025-10-22 12:34:29] llamafactory.hparams.parser:423 >> Process rank: 3, world size: 4, device: cuda:3, distributed training: True, compute dtype: torch.bfloat16
[2025-10-22 12:34:29,282] [INFO] [comm.py:821:init_distributed] cdb=None
You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.
[INFO|2025-10-22 12:34:29] llamafactory.hparams.parser:423 >> Process rank: 2, world size: 4, device: cuda:2, distributed training: True, compute dtype: torch.bfloat16
[2025-10-22 12:34:29,626] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-10-22 12:34:29,626] [INFO] [comm.py:852:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}
[INFO|2025-10-22 12:34:29] llamafactory.hparams.parser:143 >> Set `ddp_find_unused_parameters` to False in DDP training since LoRA is enabled.
[INFO|2025-10-22 12:34:29] llamafactory.hparams.parser:423 >> Process rank: 0, world size: 4, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16
[INFO|tokenization_utils_base.py:2021] 2025-10-22 12:34:29,774 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-10-22 12:34:29,774 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-10-22 12:34:29,774 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-10-22 12:34:29,774 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-10-22 12:34:29,774 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-10-22 12:34:29,774 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-10-22 12:34:29,774 >> loading file chat_template.jinja
Qwen2_5OmniToken2WavModel does not support eager attention implementation, fall back to sdpa
You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s][INFO|tokenization_utils_base.py:2299] 2025-10-22 12:34:30,200 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
[INFO|image_processing_base.py:378] 2025-10-22 12:34:30,201 >> loading configuration file /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/hf_cache/models--Qwen--Qwen2.5-Omni-7B/snapshots/ae9e1690543ffd5c0221dc27f79834d0294cba00/preprocessor_config.json
[INFO|image_processing_base.py:378] 2025-10-22 12:34:30,210 >> loading configuration file /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/hf_cache/models--Qwen--Qwen2.5-Omni-7B/snapshots/ae9e1690543ffd5c0221dc27f79834d0294cba00/preprocessor_config.json
[INFO|image_processing_base.py:433] 2025-10-22 12:34:30,211 >> Image processor Qwen2VLImageProcessor {
  "chunk_length": 300,
  "dither": 0.0,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "feature_size": 128,
  "hop_length": 160,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "n_fft": 400,
  "n_samples": 4800000,
  "nb_max_frames": 30000,
  "padding_side": "right",
  "padding_value": 0.0,
  "patch_size": 14,
  "processor_class": "Qwen2_5OmniProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_attention_mask": true,
  "sampling_rate": 16000,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

[WARNING|logging.py:328] 2025-10-22 12:34:30,212 >> You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.
[INFO|video_processing_utils.py:627] 2025-10-22 12:34:30,212 >> loading configuration file /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/hf_cache/models--Qwen--Qwen2.5-Omni-7B/snapshots/ae9e1690543ffd5c0221dc27f79834d0294cba00/preprocessor_config.json
[INFO|video_processing_utils.py:683] 2025-10-22 12:34:30,212 >> Video processor Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "chunk_length": 300,
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "dither": 0.0,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "feature_extractor_type": "WhisperFeatureExtractor",
  "feature_size": 128,
  "hop_length": 160,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "n_fft": 400,
  "n_samples": 4800000,
  "nb_max_frames": 30000,
  "padding_side": "right",
  "padding_value": 0.0,
  "patch_size": 14,
  "processor_class": "Qwen2_5OmniProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_attention_mask": true,
  "sampling_rate": 16000,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

[INFO|feature_extraction_utils.py:548] 2025-10-22 12:34:30,217 >> loading configuration file /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/hf_cache/models--Qwen--Qwen2.5-Omni-7B/snapshots/ae9e1690543ffd5c0221dc27f79834d0294cba00/preprocessor_config.json
[INFO|feature_extraction_utils.py:597] 2025-10-22 12:34:30,218 >> Feature extractor WhisperFeatureExtractor {
  "chunk_length": 300,
  "dither": 0.0,
  "feature_extractor_type": "WhisperFeatureExtractor",
  "feature_size": 128,
  "hop_length": 160,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "n_fft": 400,
  "n_samples": 4800000,
  "nb_max_frames": 30000,
  "padding_side": "right",
  "padding_value": 0.0,
  "patch_size": 14,
  "processor_class": "Qwen2_5OmniProcessor",
  "return_attention_mask": true,
  "sampling_rate": 16000,
  "temporal_patch_size": 2
}

[INFO|tokenization_utils_base.py:2021] 2025-10-22 12:34:30,219 >> loading file vocab.json
[INFO|tokenization_utils_base.py:2021] 2025-10-22 12:34:30,219 >> loading file merges.txt
[INFO|tokenization_utils_base.py:2021] 2025-10-22 12:34:30,219 >> loading file tokenizer.json
[INFO|tokenization_utils_base.py:2021] 2025-10-22 12:34:30,219 >> loading file added_tokens.json
[INFO|tokenization_utils_base.py:2021] 2025-10-22 12:34:30,219 >> loading file special_tokens_map.json
[INFO|tokenization_utils_base.py:2021] 2025-10-22 12:34:30,219 >> loading file tokenizer_config.json
[INFO|tokenization_utils_base.py:2021] 2025-10-22 12:34:30,219 >> loading file chat_template.jinja
Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}
[INFO|tokenization_utils_base.py:2299] 2025-10-22 12:34:30,646 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}
Qwen2_5OmniToken2WavModel does not support eager attention implementation, fall back to sdpa
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Qwen2_5OmniToken2WavModel does not support eager attention implementation, fall back to sdpa
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s][INFO|processing_utils.py:990] 2025-10-22 12:34:31,036 >> Processor Qwen2_5OmniProcessor:
- image_processor: Qwen2VLImageProcessor {
  "chunk_length": 300,
  "dither": 0.0,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_rescale": true,
  "do_resize": true,
  "feature_size": 128,
  "hop_length": 160,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "n_fft": 400,
  "n_samples": 4800000,
  "nb_max_frames": 30000,
  "padding_side": "right",
  "padding_value": 0.0,
  "patch_size": 14,
  "processor_class": "Qwen2_5OmniProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_attention_mask": true,
  "sampling_rate": 16000,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "temporal_patch_size": 2
}

- video_processor: Qwen2VLVideoProcessor {
  "_valid_kwargs_names": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "chunk_length": 300,
  "crop_size": null,
  "data_format": "channels_first",
  "default_to_square": true,
  "device": null,
  "dither": 0.0,
  "do_center_crop": null,
  "do_convert_rgb": true,
  "do_normalize": true,
  "do_pad": null,
  "do_rescale": true,
  "do_resize": true,
  "feature_extractor_type": "WhisperFeatureExtractor",
  "feature_size": 128,
  "hop_length": 160,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "input_data_format": null,
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "model_valid_processing_keys": [
    "do_convert_rgb",
    "do_resize",
    "size",
    "size_divisor",
    "default_to_square",
    "resample",
    "do_rescale",
    "rescale_factor",
    "do_normalize",
    "image_mean",
    "image_std",
    "do_pad",
    "do_center_crop",
    "crop_size",
    "data_format",
    "input_data_format",
    "device",
    "min_pixels",
    "max_pixels",
    "patch_size",
    "temporal_patch_size",
    "merge_size"
  ],
  "n_fft": 400,
  "n_samples": 4800000,
  "nb_max_frames": 30000,
  "padding_side": "right",
  "padding_value": 0.0,
  "patch_size": 14,
  "processor_class": "Qwen2_5OmniProcessor",
  "resample": 3,
  "rescale_factor": 0.00392156862745098,
  "return_attention_mask": true,
  "sampling_rate": 16000,
  "size": {
    "longest_edge": 12845056,
    "shortest_edge": 3136
  },
  "size_divisor": null,
  "temporal_patch_size": 2,
  "video_processor_type": "Qwen2VLVideoProcessor"
}

- feature_extractor: WhisperFeatureExtractor {
  "chunk_length": 300,
  "dither": 0.0,
  "feature_extractor_type": "WhisperFeatureExtractor",
  "feature_size": 128,
  "hop_length": 160,
  "image_mean": [
    0.48145466,
    0.4578275,
    0.40821073
  ],
  "image_processor_type": "Qwen2VLImageProcessor",
  "image_std": [
    0.26862954,
    0.26130258,
    0.27577711
  ],
  "max_pixels": 12845056,
  "merge_size": 2,
  "min_pixels": 3136,
  "n_fft": 400,
  "n_samples": 4800000,
  "nb_max_frames": 30000,
  "padding_side": "right",
  "padding_value": 0.0,
  "patch_size": 14,
  "processor_class": "Qwen2_5OmniProcessor",
  "return_attention_mask": true,
  "sampling_rate": 16000,
  "temporal_patch_size": 2
}

- tokenizer: Qwen2TokenizerFast(name_or_path='/home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/hf_cache/models--Qwen--Qwen2.5-Omni-7B/snapshots/ae9e1690543ffd5c0221dc27f79834d0294cba00', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|AUDIO|>', '<|audio_bos|>', '<|audio_eos|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_bos|>', '<|vision_eos|>', '<|vision_pad|>', '<|IMAGE|>', '<|VIDEO|>'], 'image_token': '<|IMAGE|>', 'audio_token': '<|AUDIO|>', 'video_token': '<|VIDEO|>', 'vision_bos_token': '<|vision_bos|>', 'vision_eos_token': '<|vision_eos|>', 'audio_bos_token': '<|audio_bos|>', 'audio_eos_token': '<|audio_eos|>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={
	151643: AddedToken("<|endoftext|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151644: AddedToken("<|im_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151645: AddedToken("<|im_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151646: AddedToken("<|AUDIO|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151647: AddedToken("<|audio_bos|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151648: AddedToken("<|audio_eos|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151649: AddedToken("<|box_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151650: AddedToken("<|quad_start|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151651: AddedToken("<|quad_end|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151652: AddedToken("<|vision_bos|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151653: AddedToken("<|vision_eos|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151654: AddedToken("<|vision_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151655: AddedToken("<|IMAGE|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151656: AddedToken("<|VIDEO|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	151657: AddedToken("<tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151658: AddedToken("</tool_call>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151659: AddedToken("<|fim_prefix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151660: AddedToken("<|fim_middle|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151661: AddedToken("<|fim_suffix|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151662: AddedToken("<|fim_pad|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151663: AddedToken("<|repo_name|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
	151664: AddedToken("<|file_sep|>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),
}
)

{
  "processor_class": "Qwen2_5OmniProcessor"
}

[WARNING|2025-10-22 12:34:31] llamafactory.data.loader:148 >> Loading dataset from disk will ignore other data arguments.
[INFO|2025-10-22 12:34:31] llamafactory.data.loader:143 >> Loaded tokenized dataset from /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/saves/datasets/lemon_tok_192.
[INFO|configuration_utils.py:696] 2025-10-22 12:34:31,080 >> loading configuration file /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/hf_cache/models--Qwen--Qwen2.5-Omni-7B/snapshots/ae9e1690543ffd5c0221dc27f79834d0294cba00/config.json
[WARNING|modeling_rope_utils.py:467] 2025-10-22 12:34:31,082 >> Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}
[INFO|configuration_qwen2_5_omni.py:1031] 2025-10-22 12:34:31,084 >> thinker_config is None. Initializing thinker model with default values
[INFO|configuration_qwen2_5_omni.py:1035] 2025-10-22 12:34:31,084 >> talker_config is None. Initializing talker model with default values
[INFO|configuration_qwen2_5_omni.py:1039] 2025-10-22 12:34:31,084 >> token2wav_config is None. Initializing token2wav model with default values
[INFO|configuration_utils.py:770] 2025-10-22 12:34:31,088 >> Model config Qwen2_5OmniConfig {
  "architectures": [
    "Qwen2_5OmniForConditionalGeneration"
  ],
  "enable_audio_output": true,
  "enable_talker": true,
  "model_type": "qwen2_5_omni",
  "talker_config": {
    "_name_or_path": "Qwen2.5-Omni-7B/talker",
    "architectures": [
      "Qwen2OmniTalkerForConditionalGeneration"
    ],
    "attention_dropout": 0.0,
    "audio_end_token_id": 151648,
    "audio_start_token_id": 151647,
    "audio_token_index": 151646,
    "embedding_size": 3584,
    "head_dim": 128,
    "hidden_act": "silu",
    "hidden_size": 896,
    "image_token_index": 151655,
    "init_std": 0.02,
    "initializer_range": 0.02,
    "intermediate_size": 18944,
    "max_position_embeddings": 32768,
    "max_window_layers": 28,
    "model_type": "qwen2_5_omni_talker",
    "num_attention_heads": 12,
    "num_hidden_layers": 24,
    "num_key_value_heads": 4,
    "position_id_per_seconds": 25,
    "rms_norm_eps": 1e-06,
    "rope_scaling": {
      "mrope_section": [
        16,
        24,
        24
      ],
      "rope_type": "default",
      "type": "default"
    },
    "rope_theta": 1000000.0,
    "seconds_per_chunk": 0.4,
    "sliding_window": 32768,
    "spatial_merge_size": 2,
    "torch_dtype": "bfloat16",
    "tts_codec_end_token_id": 8294,
    "tts_codec_mask_token_id": 8296,
    "tts_codec_pad_token_id": 8292,
    "tts_codec_start_token_id": 8293,
    "tts_text_end_token_id": 151861,
    "tts_text_pad_token_id": 151859,
    "tts_text_start_token_id": 151860,
    "use_cache": true,
    "use_sliding_window": false,
    "video_token_index": 151656,
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vocab_size": 8448
  },
  "thinker_config": {
    "_name_or_path": "Qwen2.5-Omni-7B/thinker",
    "architectures": [
      "Qwen2OmniNaViTThinkerForConditionalGeneration"
    ],
    "audio_config": {
      "_name_or_path": "",
      "activation_dropout": 0.0,
      "activation_function": "gelu",
      "add_cross_attention": false,
      "architectures": null,
      "attention_dropout": 0.0,
      "bad_words_ids": null,
      "begin_suppress_tokens": null,
      "bos_token_id": null,
      "chunk_size_feed_forward": 0,
      "cross_attention_hidden_size": null,
      "d_model": 1280,
      "decoder_start_token_id": null,
      "diversity_penalty": 0.0,
      "do_sample": false,
      "dropout": 0.0,
      "early_stopping": false,
      "encoder_attention_heads": 20,
      "encoder_ffn_dim": 5120,
      "encoder_layerdrop": 0.0,
      "encoder_layers": 32,
      "encoder_no_repeat_ngram_size": 0,
      "eos_token_id": null,
      "exponential_decay_length_penalty": null,
      "finetuning_task": null,
      "forced_bos_token_id": null,
      "forced_eos_token_id": null,
      "id2label": {
        "0": "LABEL_0",
        "1": "LABEL_1"
      },
      "init_std": 0.02,
      "initializer_range": 0.02,
      "is_decoder": false,
      "is_encoder_decoder": false,
      "label2id": {
        "LABEL_0": 0,
        "LABEL_1": 1
      },
      "length_penalty": 1.0,
      "max_length": 20,
      "max_source_positions": 1500,
      "min_length": 0,
      "model_type": "qwen2_5_omni_audio_encoder",
      "n_window": 100,
      "no_repeat_ngram_size": 0,
      "num_beam_groups": 1,
      "num_beams": 1,
      "num_hidden_layers": 32,
      "num_mel_bins": 128,
      "num_return_sequences": 1,
      "output_attentions": false,
      "output_dim": 3584,
      "output_hidden_states": false,
      "output_scores": false,
      "pad_token_id": null,
      "prefix": null,
      "problem_type": null,
      "pruned_heads": {},
      "remove_invalid_values": false,
      "repetition_penalty": 1.0,
      "return_dict": true,
      "return_dict_in_generate": false,
      "scale_embedding": false,
      "sep_token_id": null,
      "suppress_tokens": null,
      "task_specific_params": null,
      "temperature": 1.0,
      "tf_legacy_loss": false,
      "tie_encoder_decoder": false,
      "tie_word_embeddings": true,
      "tokenizer_class": null,
      "top_k": 50,
      "top_p": 1.0,
      "torch_dtype": null,
      "torchscript": false,
      "typical_p": 1.0,
      "use_bfloat16": false
    },
    "audio_end_token_id": 151648,
    "audio_start_token_id": 151647,
    "audio_token_index": 151646,
    "bos_token_id": 151644,
    "eos_token_id": 151645,
    "ignore_index": -100,
    "image_token_index": 151655,
    "init_std": 0.02,
    "initializer_range": 0.02,
    "model_type": "qwen2_5_omni_thinker",
    "pad_token_id": 151643,
    "position_id_per_seconds": 25,
    "seconds_per_chunk": 0.4,
    "text_config": {
      "_name_or_path": "",
      "add_cross_attention": false,
      "architectures": null,
      "attention_dropout": 0.0,
      "bad_words_ids": null,
      "begin_suppress_tokens": null,
      "bos_token_id": null,
      "chunk_size_feed_forward": 0,
      "cross_attention_hidden_size": null,
      "decoder_start_token_id": null,
      "diversity_penalty": 0.0,
      "do_sample": false,
      "early_stopping": false,
      "encoder_no_repeat_ngram_size": 0,
      "eos_token_id": null,
      "exponential_decay_length_penalty": null,
      "finetuning_task": null,
      "forced_bos_token_id": null,
      "forced_eos_token_id": null,
      "hidden_act": "silu",
      "hidden_size": 3584,
      "id2label": {
        "0": "LABEL_0",
        "1": "LABEL_1"
      },
      "init_std": 0.02,
      "initializer_range": 0.02,
      "intermediate_size": 18944,
      "is_decoder": false,
      "is_encoder_decoder": false,
      "label2id": {
        "LABEL_0": 0,
        "LABEL_1": 1
      },
      "length_penalty": 1.0,
      "max_length": 20,
      "max_position_embeddings": 32768,
      "max_window_layers": 28,
      "min_length": 0,
      "model_type": "qwen2_5_omni_text",
      "no_repeat_ngram_size": 0,
      "num_attention_heads": 28,
      "num_beam_groups": 1,
      "num_beams": 1,
      "num_hidden_layers": 28,
      "num_key_value_heads": 4,
      "num_return_sequences": 1,
      "output_attentions": false,
      "output_hidden_states": false,
      "output_scores": false,
      "pad_token_id": null,
      "prefix": null,
      "problem_type": null,
      "pruned_heads": {},
      "remove_invalid_values": false,
      "repetition_penalty": 1.0,
      "return_dict": true,
      "return_dict_in_generate": false,
      "rms_norm_eps": 1e-06,
      "rope_scaling": {
        "mrope_section": [
          16,
          24,
          24
        ],
        "rope_type": "default",
        "type": "default"
      },
      "rope_theta": 1000000.0,
      "sep_token_id": null,
      "sliding_window": 32768,
      "suppress_tokens": null,
      "task_specific_params": null,
      "temperature": 1.0,
      "tf_legacy_loss": false,
      "tie_encoder_decoder": false,
      "tie_word_embeddings": false,
      "tokenizer_class": null,
      "top_k": 50,
      "top_p": 1.0,
      "torch_dtype": null,
      "torchscript": false,
      "typical_p": 1.0,
      "use_bfloat16": false,
      "use_cache": true,
      "use_sliding_window": false,
      "vocab_size": 152064
    },
    "torch_dtype": "bfloat16",
    "user_token_id": 872,
    "video_token_index": 151656,
    "vision_config": {
      "_name_or_path": "",
      "add_cross_attention": false,
      "architectures": null,
      "bad_words_ids": null,
      "begin_suppress_tokens": null,
      "bos_token_id": null,
      "chunk_size_feed_forward": 0,
      "cross_attention_hidden_size": null,
      "decoder_start_token_id": null,
      "depth": 32,
      "diversity_penalty": 0.0,
      "do_sample": false,
      "early_stopping": false,
      "embed_dim": 1280,
      "encoder_no_repeat_ngram_size": 0,
      "eos_token_id": null,
      "exponential_decay_length_penalty": null,
      "finetuning_task": null,
      "forced_bos_token_id": null,
      "forced_eos_token_id": null,
      "fullatt_block_indexes": [
        7,
        15,
        23,
        31
      ],
      "hidden_act": "silu",
      "hidden_size": 1280,
      "id2label": {
        "0": "LABEL_0",
        "1": "LABEL_1"
      },
      "in_channels": 3,
      "in_chans": 3,
      "init_std": 0.02,
      "initializer_range": 0.02,
      "intermediate_size": 3420,
      "is_decoder": false,
      "is_encoder_decoder": false,
      "label2id": {
        "LABEL_0": 0,
        "LABEL_1": 1
      },
      "length_penalty": 1.0,
      "max_length": 20,
      "min_length": 0,
      "model_type": "qwen2_5_omni_vision_encoder",
      "no_repeat_ngram_size": 0,
      "num_beam_groups": 1,
      "num_beams": 1,
      "num_heads": 16,
      "num_return_sequences": 1,
      "out_hidden_size": 3584,
      "output_attentions": false,
      "output_hidden_states": false,
      "output_scores": false,
      "pad_token_id": null,
      "patch_size": 14,
      "prefix": null,
      "problem_type": null,
      "pruned_heads": {},
      "remove_invalid_values": false,
      "repetition_penalty": 1.0,
      "return_dict": true,
      "return_dict_in_generate": false,
      "sep_token_id": null,
      "spatial_merge_size": 2,
      "spatial_patch_size": 14,
      "suppress_tokens": null,
      "task_specific_params": null,
      "temperature": 1.0,
      "temporal_patch_size": 2,
      "tf_legacy_loss": false,
      "tie_encoder_decoder": false,
      "tie_word_embeddings": true,
      "tokenizer_class": null,
      "tokens_per_second": 25,
      "top_k": 50,
      "top_p": 1.0,
      "torch_dtype": null,
      "torchscript": false,
      "typical_p": 1.0,
      "use_bfloat16": false,
      "window_size": 112
    },
    "vision_end_token_id": 151653,
    "vision_start_token_id": 151652,
    "vision_token_id": 151654
  },
  "token2wav_config": {
    "bigvgan_config": {
      "_name_or_path": "",
      "add_cross_attention": false,
      "architectures": null,
      "bad_words_ids": null,
      "begin_suppress_tokens": null,
      "bos_token_id": null,
      "chunk_size_feed_forward": 0,
      "cross_attention_hidden_size": null,
      "decoder_start_token_id": null,
      "diversity_penalty": 0.0,
      "do_sample": false,
      "early_stopping": false,
      "encoder_no_repeat_ngram_size": 0,
      "eos_token_id": null,
      "exponential_decay_length_penalty": null,
      "finetuning_task": null,
      "forced_bos_token_id": null,
      "forced_eos_token_id": null,
      "id2label": {
        "0": "LABEL_0",
        "1": "LABEL_1"
      },
      "is_decoder": false,
      "is_encoder_decoder": false,
      "label2id": {
        "LABEL_0": 0,
        "LABEL_1": 1
      },
      "length_penalty": 1.0,
      "max_length": 20,
      "mel_dim": 80,
      "min_length": 0,
      "model_type": "qwen2_5_omni_bigvgan",
      "no_repeat_ngram_size": 0,
      "num_beam_groups": 1,
      "num_beams": 1,
      "num_return_sequences": 1,
      "output_attentions": false,
      "output_hidden_states": false,
      "output_scores": false,
      "pad_token_id": null,
      "prefix": null,
      "problem_type": null,
      "pruned_heads": {},
      "remove_invalid_values": false,
      "repetition_penalty": 1.0,
      "resblock_dilation_sizes": [
        [
          1,
          3,
          5
        ],
        [
          1,
          3,
          5
        ],
        [
          1,
          3,
          5
        ]
      ],
      "resblock_kernel_sizes": [
        3,
        7,
        11
      ],
      "return_dict": true,
      "return_dict_in_generate": false,
      "sep_token_id": null,
      "suppress_tokens": null,
      "task_specific_params": null,
      "temperature": 1.0,
      "tf_legacy_loss": false,
      "tie_encoder_decoder": false,
      "tie_word_embeddings": true,
      "tokenizer_class": null,
      "top_k": 50,
      "top_p": 1.0,
      "torch_dtype": null,
      "torchscript": false,
      "typical_p": 1.0,
      "upsample_initial_channel": 1536,
      "upsample_kernel_sizes": [
        11,
        7,
        4,
        4,
        4,
        4
      ],
      "upsample_rates": [
        5,
        3,
        2,
        2,
        2,
        2
      ],
      "use_bfloat16": false,
      "use_bias_at_final": false
    },
    "dit_config": {
      "_name_or_path": "",
      "add_cross_attention": false,
      "architectures": null,
      "bad_words_ids": null,
      "begin_suppress_tokens": null,
      "block_size": 24,
      "bos_token_id": null,
      "chunk_size_feed_forward": 0,
      "cross_attention_hidden_size": null,
      "decoder_start_token_id": null,
      "depth": 22,
      "dim": 1024,
      "diversity_penalty": 0.0,
      "do_sample": false,
      "dropout": 0.1,
      "early_stopping": false,
      "emb_dim": 512,
      "enc_attention_channels": 64,
      "enc_channels": [
        256,
        256,
        256,
        256,
        768
      ],
      "enc_dilations": [
        1,
        2,
        3,
        4,
        1
      ],
      "enc_dim": 128,
      "enc_emb_dim": 192,
      "enc_global_context": true,
      "enc_kernel_sizes": [
        5,
        3,
        3,
        3,
        1
      ],
      "enc_lin_neurons": 192,
      "enc_res2net_scale": 2,
      "enc_se_channels": 64,
      "encoder_no_repeat_ngram_size": 0,
      "eos_token_id": null,
      "exponential_decay_length_penalty": null,
      "ff_mult": 2,
      "finetuning_task": null,
      "forced_bos_token_id": null,
      "forced_eos_token_id": null,
      "head_dim": 64,
      "heads": 16,
      "hidden_size": 1024,
      "id2label": {
        "0": "LABEL_0",
        "1": "LABEL_1"
      },
      "is_decoder": false,
      "is_encoder_decoder": false,
      "label2id": {
        "LABEL_0": 0,
        "LABEL_1": 1
      },
      "length_penalty": 1.0,
      "look_ahead_layers": [
        10
      ],
      "look_backward_layers": [
        0,
        20
      ],
      "max_length": 20,
      "max_position_embeddings": 32768,
      "mel_dim": 80,
      "min_length": 0,
      "model_type": "qwen2_5_omni_dit",
      "no_repeat_ngram_size": 0,
      "num_attention_heads": 16,
      "num_beam_groups": 1,
      "num_beams": 1,
      "num_embeds": 8193,
      "num_hidden_layers": 22,
      "num_return_sequences": 1,
      "output_attentions": false,
      "output_hidden_states": false,
      "output_scores": false,
      "pad_token_id": null,
      "prefix": null,
      "problem_type": null,
      "pruned_heads": {},
      "remove_invalid_values": false,
      "repeats": 2,
      "repetition_penalty": 1.0,
      "return_dict": true,
      "return_dict_in_generate": false,
      "rope_theta": 10000.0,
      "sep_token_id": null,
      "suppress_tokens": null,
      "task_specific_params": null,
      "temperature": 1.0,
      "tf_legacy_loss": false,
      "tie_encoder_decoder": false,
      "tie_word_embeddings": true,
      "tokenizer_class": null,
      "top_k": 50,
      "top_p": 1.0,
      "torch_dtype": "float32",
      "torchscript": false,
      "typical_p": 1.0,
      "use_bfloat16": false
    },
    "model_type": "qwen2_5_omni_token2wav"
  },
  "torch_dtype": "bfloat16",
  "transformers_version": "4.52.2"
}

[INFO|2025-10-22 12:34:31] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.
[INFO|modeling_utils.py:1147] 2025-10-22 12:34:31,206 >> loading weights file /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/hf_cache/models--Qwen--Qwen2.5-Omni-7B/snapshots/ae9e1690543ffd5c0221dc27f79834d0294cba00/model.safetensors.index.json
[INFO|modeling_utils.py:2240] 2025-10-22 12:34:31,207 >> Instantiating Qwen2_5OmniForConditionalGeneration model under default dtype torch.bfloat16.
[INFO|configuration_utils.py:1135] 2025-10-22 12:34:31,211 >> Generate config GenerationConfig {
  "use_cache": false
}

[INFO|configuration_utils.py:1135] 2025-10-22 12:34:31,212 >> Generate config GenerationConfig {
  "bos_token_id": 151644,
  "eos_token_id": 151645,
  "pad_token_id": 151643
}

[INFO|configuration_utils.py:1135] 2025-10-22 12:34:31,255 >> Generate config GenerationConfig {}

[WARNING|logging.py:328] 2025-10-22 12:34:31,266 >> Qwen2_5OmniToken2WavModel does not support eager attention implementation, fall back to sdpa
[INFO|modeling_utils.py:2240] 2025-10-22 12:34:31,266 >> Instantiating Qwen2_5OmniToken2WavDiTModel model under default dtype torch.float32.
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:01<00:06,  1.63s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:01<00:05,  1.40s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:01<00:05,  1.33s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:02<00:03,  1.29s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:02<00:03,  1.10s/it]Loading checkpoint shards:  20%|██        | 1/5 [00:01<00:06,  1.75s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:02<00:03,  1.04s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:03<00:02,  1.19s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:03<00:01,  1.04it/s]Loading checkpoint shards:  60%|██████    | 3/5 [00:03<00:02,  1.02s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:02<00:03,  1.24s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:04<00:01,  1.16s/it]Loading checkpoint shards:  60%|██████    | 3/5 [00:03<00:02,  1.08s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:04<00:01,  1.05s/it]Loading checkpoint shards:  80%|████████  | 4/5 [00:04<00:01,  1.09s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:05<00:00,  1.05s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:05<00:00,  1.15s/it]
Loading checkpoint shards:  80%|████████  | 4/5 [00:04<00:01,  1.02s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:05<00:00,  1.01it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:05<00:00,  1.02s/it]Loading checkpoint shards: 100%|██████████| 5/5 [00:05<00:00,  1.01s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:05<00:00,  1.06s/it]
Loading checkpoint shards: 100%|██████████| 5/5 [00:05<00:00,  1.08it/s]Loading checkpoint shards: 100%|██████████| 5/5 [00:05<00:00,  1.04s/it]
[INFO|modeling_utils.py:5130] 2025-10-22 12:34:36,629 >> All model checkpoint weights were used when initializing Qwen2_5OmniForConditionalGeneration.

[INFO|modeling_utils.py:5138] 2025-10-22 12:34:36,629 >> All the weights of Qwen2_5OmniForConditionalGeneration were initialized from the model checkpoint at /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/hf_cache/models--Qwen--Qwen2.5-Omni-7B/snapshots/ae9e1690543ffd5c0221dc27f79834d0294cba00.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2_5OmniForConditionalGeneration for predictions without further training.
[INFO|configuration_utils.py:1088] 2025-10-22 12:34:36,639 >> loading configuration file /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/hf_cache/models--Qwen--Qwen2.5-Omni-7B/snapshots/ae9e1690543ffd5c0221dc27f79834d0294cba00/generation_config.json
[INFO|configuration_utils.py:1135] 2025-10-22 12:34:36,639 >> Generate config GenerationConfig {}

[INFO|modeling_qwen2_5_omni.py:4755] 2025-10-22 12:34:36,675 >> Speaker ['Ethan', 'Chelsie'] loaded
[INFO|2025-10-22 12:34:36] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.
[INFO|2025-10-22 12:34:36] llamafactory.model.model_utils.attention:143 >> Using vanilla attention implementation.
[INFO|2025-10-22 12:34:36] llamafactory.model.adapter:143 >> Upcasting trainable params to float32.
[INFO|2025-10-22 12:34:36] llamafactory.model.adapter:143 >> Fine-tuning method: LoRA
[INFO|2025-10-22 12:34:36] llamafactory.model.model_utils.misc:143 >> Found linear modules: o_proj,q_proj,v_proj,gate_proj,k_proj,up_proj,down_proj
[INFO|2025-10-22 12:34:36] llamafactory.model.model_utils.visual:143 >> Set vision model not trainable: ['visual.patch_embed', 'visual.blocks', 'audio_tower'].
[INFO|2025-10-22 12:34:36] llamafactory.model.model_utils.visual:143 >> Set multi model projector not trainable: visual.merger.
[INFO|2025-10-22 12:34:37] llamafactory.model.loader:143 >> trainable params: 40,370,176 || all params: 8,972,184,064 || trainable%: 0.4499
name: base_model.model.audio_tower.conv1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.conv1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.conv2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.conv2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.audio_bos_eos_token.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.0.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.0.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.0.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.0.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.0.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.0.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.0.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.0.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.0.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.0.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.0.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.0.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.0.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.0.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.0.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.1.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.1.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.1.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.1.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.1.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.1.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.1.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.1.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.1.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.1.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.1.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.1.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.1.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.1.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.1.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.2.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.2.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.2.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.2.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.2.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.2.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.2.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.2.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.2.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.2.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.2.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.2.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.2.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.2.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.2.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.3.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.3.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.3.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.3.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.3.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.3.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.3.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.3.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.3.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.3.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.3.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.3.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.3.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.3.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.3.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.4.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.4.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.4.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.4.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.4.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.4.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.4.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.4.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.4.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.4.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.4.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.4.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.4.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.4.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.4.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.5.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.5.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.5.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.5.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.5.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.5.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.5.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.5.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.5.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.5.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.5.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.5.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.5.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.5.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.5.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.6.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.6.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.6.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.6.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.6.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.6.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.6.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.6.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.6.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.6.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.6.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.6.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.6.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.6.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.6.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.7.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.7.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.7.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.7.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.7.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.7.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.7.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.7.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.7.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.7.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.7.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.7.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.7.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.7.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.7.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.8.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.8.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.8.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.8.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.8.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.8.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.8.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.8.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.8.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.8.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.8.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.8.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.8.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.8.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.8.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.9.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.9.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.9.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.9.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.9.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.9.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.9.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.9.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.9.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.9.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.9.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.9.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.9.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.9.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.9.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.10.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.10.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.10.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.10.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.10.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.10.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.10.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.10.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.10.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.10.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.10.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.10.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.10.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.10.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.10.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.11.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.11.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.11.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.11.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.11.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.11.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.11.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.11.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.11.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.11.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.11.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.11.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.11.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.11.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.11.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.12.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.12.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.12.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.12.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.12.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.12.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.12.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.12.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.12.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.12.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.12.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.12.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.12.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.12.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.12.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.13.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.13.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.13.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.13.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.13.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.13.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.13.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.13.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.13.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.13.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.13.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.13.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.13.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.13.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.13.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.14.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.14.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.14.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.14.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.14.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.14.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.14.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.14.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.14.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.14.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.14.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.14.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.14.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.14.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.14.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.15.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.15.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.15.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.15.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.15.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.15.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.15.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.15.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.15.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.15.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.15.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.15.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.15.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.15.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.15.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.16.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.16.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.16.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.16.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.16.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.16.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.16.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.16.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.16.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.16.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.16.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.16.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.16.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.16.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.16.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.17.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.17.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.17.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.17.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.17.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.17.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.17.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.17.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.17.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.17.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.17.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.17.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.17.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.17.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.17.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.18.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.18.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.18.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.18.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.18.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.18.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.18.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.18.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.18.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.18.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.18.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.18.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.18.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.18.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.18.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.19.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.19.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.19.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.19.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.19.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.19.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.19.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.19.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.19.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.19.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.19.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.19.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.19.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.19.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.19.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.20.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.20.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.20.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.20.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.20.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.20.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.20.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.20.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.20.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.20.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.20.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.20.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.20.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.20.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.20.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.21.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.21.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.21.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.21.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.21.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.21.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.21.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.21.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.21.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.21.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.21.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.21.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.21.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.21.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.21.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.22.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.22.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.22.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.22.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.22.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.22.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.22.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.22.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.22.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.22.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.22.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.22.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.22.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.22.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.22.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.23.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.23.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.23.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.23.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.23.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.23.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.23.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.23.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.23.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.23.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.23.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.23.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.23.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.23.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.23.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.24.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.24.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.24.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.24.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.24.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.24.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.24.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.24.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.24.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.24.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.24.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.24.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.24.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.24.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.24.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.25.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.25.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.25.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.25.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.25.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.25.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.25.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.25.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.25.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.25.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.25.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.25.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.25.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.25.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.25.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.26.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.26.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.26.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.26.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.26.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.26.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.26.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.26.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.26.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.26.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.26.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.26.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.26.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.26.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.26.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.27.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.27.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.27.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.27.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.27.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.27.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.27.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.27.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.27.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.27.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.27.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.27.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.27.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.27.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.27.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.28.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.28.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.28.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.28.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.28.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.28.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.28.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.28.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.28.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.28.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.28.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.28.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.28.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.28.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.28.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.29.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.29.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.29.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.29.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.29.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.29.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.29.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.29.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.29.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.29.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.29.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.29.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.29.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.29.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.29.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.30.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.30.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.30.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.30.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.30.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.30.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.30.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.30.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.30.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.30.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.30.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.30.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.30.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.30.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.30.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.31.self_attn.k_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.31.self_attn.v_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.31.self_attn.v_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.31.self_attn.q_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.31.self_attn.q_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.31.self_attn.out_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.31.self_attn.out_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.31.self_attn_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.31.self_attn_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.31.fc1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.31.fc1.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.31.fc2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.31.fc2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.31.final_layer_norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.layers.31.final_layer_norm.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.ln_post.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.ln_post.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.audio_tower.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.patch_embed.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.0.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.0.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.0.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.0.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.0.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.0.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.0.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.0.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.0.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.0.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.0.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.0.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.0.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.0.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.0.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.0.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.1.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.1.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.1.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.1.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.1.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.1.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.1.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.1.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.1.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.1.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.1.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.1.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.1.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.1.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.1.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.1.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.2.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.2.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.2.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.2.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.2.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.2.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.2.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.2.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.2.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.2.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.2.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.2.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.2.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.2.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.2.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.2.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.3.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.3.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.3.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.3.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.3.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.3.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.3.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.3.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.3.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.3.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.3.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.3.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.3.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.3.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.3.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.3.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.4.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.4.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.4.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.4.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.4.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.4.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.4.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.4.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.4.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.4.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.4.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.4.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.4.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.4.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.4.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.4.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.5.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.5.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.5.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.5.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.5.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.5.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.5.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.5.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.5.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.5.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.5.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.5.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.5.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.5.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.5.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.5.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.6.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.6.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.6.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.6.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.6.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.6.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.6.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.6.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.6.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.6.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.6.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.6.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.6.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.6.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.6.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.6.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.7.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.7.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.7.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.7.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.7.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.7.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.7.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.7.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.7.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.7.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.7.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.7.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.7.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.7.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.7.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.7.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.8.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.8.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.8.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.8.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.8.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.8.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.8.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.8.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.8.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.8.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.8.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.8.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.8.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.8.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.8.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.8.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.9.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.9.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.9.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.9.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.9.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.9.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.9.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.9.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.9.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.9.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.9.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.9.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.9.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.9.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.9.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.9.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.10.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.10.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.10.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.10.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.10.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.10.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.10.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.10.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.10.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.10.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.10.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.10.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.10.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.10.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.10.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.10.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.11.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.11.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.11.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.11.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.11.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.11.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.11.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.11.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.11.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.11.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.11.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.11.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.11.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.11.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.11.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.11.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.12.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.12.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.12.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.12.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.12.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.12.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.12.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.12.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.12.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.12.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.12.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.12.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.12.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.12.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.12.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.12.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.13.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.13.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.13.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.13.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.13.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.13.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.13.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.13.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.13.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.13.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.13.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.13.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.13.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.13.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.13.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.13.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.14.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.14.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.14.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.14.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.14.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.14.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.14.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.14.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.14.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.14.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.14.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.14.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.14.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.14.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.14.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.14.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.15.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.15.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.15.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.15.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.15.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.15.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.15.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.15.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.15.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.15.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.15.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.15.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.15.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.15.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.15.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.15.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.16.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.16.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.16.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.16.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.16.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.16.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.16.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.16.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.16.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.16.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.16.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.16.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.16.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.16.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.16.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.16.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.17.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.17.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.17.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.17.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.17.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.17.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.17.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.17.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.17.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.17.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.17.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.17.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.17.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.17.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.17.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.17.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.18.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.18.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.18.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.18.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.18.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.18.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.18.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.18.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.18.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.18.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.18.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.18.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.18.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.18.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.18.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.18.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.19.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.19.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.19.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.19.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.19.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.19.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.19.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.19.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.19.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.19.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.19.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.19.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.19.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.19.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.19.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.19.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.20.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.20.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.20.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.20.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.20.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.20.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.20.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.20.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.20.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.20.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.20.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.20.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.20.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.20.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.20.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.20.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.21.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.21.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.21.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.21.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.21.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.21.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.21.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.21.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.21.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.21.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.21.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.21.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.21.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.21.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.21.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.21.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.22.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.22.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.22.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.22.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.22.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.22.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.22.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.22.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.22.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.22.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.22.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.22.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.22.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.22.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.22.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.22.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.23.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.23.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.23.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.23.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.23.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.23.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.23.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.23.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.23.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.23.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.23.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.23.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.23.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.23.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.23.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.23.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.24.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.24.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.24.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.24.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.24.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.24.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.24.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.24.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.24.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.24.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.24.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.24.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.24.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.24.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.24.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.24.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.25.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.25.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.25.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.25.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.25.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.25.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.25.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.25.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.25.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.25.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.25.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.25.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.25.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.25.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.25.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.25.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.26.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.26.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.26.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.26.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.26.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.26.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.26.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.26.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.26.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.26.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.26.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.26.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.26.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.26.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.26.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.26.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.27.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.27.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.27.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.27.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.27.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.27.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.27.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.27.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.27.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.27.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.27.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.27.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.27.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.27.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.27.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.27.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.28.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.28.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.28.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.28.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.28.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.28.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.28.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.28.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.28.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.28.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.28.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.28.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.28.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.28.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.28.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.28.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.29.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.29.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.29.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.29.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.29.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.29.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.29.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.29.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.29.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.29.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.29.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.29.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.29.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.29.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.29.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.29.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.30.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.30.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.30.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.30.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.30.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.30.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.30.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.30.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.30.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.30.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.30.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.30.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.30.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.30.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.30.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.30.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.31.norm1.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.31.norm2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.31.attn.q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.31.attn.q.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.31.attn.k.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.31.attn.k.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.31.attn.v.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.31.attn.v.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.31.attn.proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.31.attn.proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.31.mlp.gate_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.31.mlp.gate_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.31.mlp.up_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.31.mlp.up_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.31.mlp.down_proj.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.blocks.31.mlp.down_proj.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.merger.ln_q.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.merger.mlp.0.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.merger.mlp.0.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.merger.mlp.2.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.visual.merger.mlp.2.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.embed_tokens.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.0.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.0.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.0.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.0.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.0.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.0.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.0.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.0.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.0.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.1.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.1.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.1.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.1.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.1.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.1.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.1.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.1.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.1.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.2.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.2.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.2.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.2.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.2.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.2.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.2.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.2.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.2.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.3.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.3.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.3.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.3.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.3.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.3.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.3.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.3.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.3.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.4.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.4.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.4.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.4.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.4.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.4.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.4.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.4.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.4.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.5.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.5.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.5.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.5.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.5.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.5.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.5.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.5.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.5.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.6.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.6.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.6.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.6.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.6.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.6.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.6.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.6.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.6.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.7.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.7.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.7.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.7.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.7.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.7.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.7.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.7.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.7.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.8.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.8.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.8.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.8.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.8.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.8.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.8.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.8.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.8.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.9.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.9.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.9.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.9.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.9.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.9.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.9.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.9.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.9.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.10.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.10.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.10.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.10.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.10.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.10.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.10.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.10.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.10.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.11.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.11.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.11.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.11.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.11.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.11.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.11.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.11.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.11.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.12.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.12.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.12.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.12.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.12.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.12.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.12.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.12.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.12.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.13.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.13.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.13.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.13.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.13.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.13.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.13.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.13.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.13.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.14.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.14.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.14.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.14.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.14.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.14.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.14.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.14.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.14.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.15.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.15.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.15.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.15.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.15.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.15.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.15.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.15.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.15.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.16.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.16.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.16.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.16.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.16.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.16.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.16.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.16.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.16.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.16.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.17.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.17.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.17.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.17.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.17.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.17.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.17.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.17.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.17.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.17.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.18.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.18.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.18.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.18.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.18.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.18.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.18.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.18.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.18.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.18.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.19.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.19.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.19.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.19.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.19.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.19.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.19.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.19.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.19.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.19.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.20.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.20.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.20.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.20.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.20.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.20.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.20.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.20.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.20.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.20.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.21.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.21.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.21.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.21.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.21.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.21.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.21.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.21.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.21.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.21.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.22.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.22.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.22.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.22.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.22.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.22.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.22.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.22.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.22.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.22.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.23.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.23.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.23.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.23.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.23.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.23.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.23.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.23.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.23.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.23.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.24.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.24.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.24.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.24.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.24.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.24.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.24.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.24.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.24.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.24.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.24.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.24.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.24.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.24.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.24.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.24.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.24.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.24.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.25.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.25.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.25.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.25.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.25.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.25.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.25.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.25.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.25.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.25.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.25.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.25.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.25.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.25.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.25.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.25.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.25.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.25.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.26.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.26.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.26.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.26.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.26.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.26.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.26.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.26.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.26.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.26.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.26.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.26.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.26.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.26.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.26.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.26.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.26.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.26.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.27.self_attn.q_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.27.self_attn.k_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.27.self_attn.k_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.27.self_attn.v_proj.base_layer.bias, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.27.self_attn.o_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.27.self_attn.o_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.27.self_attn.o_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.27.mlp.gate_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.27.mlp.gate_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.27.mlp.gate_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.27.mlp.up_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.27.mlp.up_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.27.mlp.up_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.27.mlp.down_proj.base_layer.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.27.mlp.down_proj.lora_A.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.27.mlp.down_proj.lora_B.default.weight, dtype: torch.float32, device: cuda:0, trainable: True
name: base_model.model.model.layers.27.input_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.layers.27.post_attention_layernorm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.model.norm.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
name: base_model.model.lm_head.weight, dtype: torch.bfloat16, device: cuda:0, trainable: False
[INFO|trainer.py:706] 2025-10-22 12:34:37,302 >> max_steps is given, it will override any value given in num_train_epochs
[INFO|trainer.py:756] 2025-10-22 12:34:37,302 >> Using auto half precision backend
Gradient accumulation steps mismatch: GradientAccumulationPlugin has 1, DeepSpeed config has 8. Using DeepSpeed's value.
[2025-10-22 12:34:37,661] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed info: version=0.17.4, git-hash=unknown, git-branch=unknown
[2025-10-22 12:34:37,661] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 4
[2025-10-22 12:34:37,704] [INFO] [engine.py:1339:_configure_distributed_model] ********** distributed groups summary **********
	 self.dp_world_size=4
	 self.mp_world_size=1
	 self.seq_dp_world_size=4
	 self.sequence_parallel_size=1
***********************************************
[2025-10-22 12:34:38,234] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2025-10-22 12:34:38,239] [INFO] [logging.py:107:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2025-10-22 12:34:38,239] [INFO] [logging.py:107:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2025-10-22 12:34:38,293] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2025-10-22 12:34:38,293] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>
[2025-10-22 12:34:38,293] [INFO] [logging.py:107:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2025-10-22 12:34:38,293] [INFO] [stage_1_and_2.py:172:__init__] Reduce bucket size 500000000
[2025-10-22 12:34:38,293] [INFO] [stage_1_and_2.py:173:__init__] Allgather bucket size 500000000
[2025-10-22 12:34:38,293] [INFO] [stage_1_and_2.py:174:__init__] CPU Offload: False
[2025-10-22 12:34:38,293] [INFO] [stage_1_and_2.py:175:__init__] Round robin gradient partitioning: False
[2025-10-22 12:34:39,304] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states
[2025-10-22 12:34:39,304] [INFO] [utils.py:782:see_memory_usage] MA 16.75 GB         Max_MA 16.77 GB         CA 16.81 GB         Max_CA 17 GB 
[2025-10-22 12:34:39,304] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 41.36 GB, percent = 8.2%
[2025-10-22 12:34:39,551] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states
[2025-10-22 12:34:39,552] [INFO] [utils.py:782:see_memory_usage] MA 16.75 GB         Max_MA 16.79 GB         CA 16.85 GB         Max_CA 17 GB 
[2025-10-22 12:34:39,552] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 41.55 GB, percent = 8.3%
[2025-10-22 12:34:39,552] [INFO] [stage_1_and_2.py:599:__init__] optimizer state initialized
[2025-10-22 12:34:39,796] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer
[2025-10-22 12:34:39,796] [INFO] [utils.py:782:see_memory_usage] MA 16.75 GB         Max_MA 16.75 GB         CA 16.85 GB         Max_CA 17 GB 
[2025-10-22 12:34:39,796] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 41.71 GB, percent = 8.3%
[2025-10-22 12:34:39,798] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer
[2025-10-22 12:34:39,799] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = None
[2025-10-22 12:34:39,799] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed LR Scheduler = None
[2025-10-22 12:34:39,799] [INFO] [logging.py:107:log_dist] [Rank 0] step=0, skipped=0, lr=[0.0], mom=[(0.9, 0.999)]
[2025-10-22 12:34:39,803] [INFO] [logging.py:107:log_dist] [Rank 0] [TorchCheckpointEngine] Initialized with serialization = True
[2025-10-22 12:34:39,803] [INFO] [config.py:954:print] DeepSpeedEngine configuration:
[2025-10-22 12:34:39,804] [INFO] [config.py:958:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-10-22 12:34:39,804] [INFO] [config.py:958:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'intra_op_parallelism': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[2025-10-22 12:34:39,804] [INFO] [config.py:958:print]   amp_enabled .................. False
[2025-10-22 12:34:39,804] [INFO] [config.py:958:print]   amp_params ................... False
[2025-10-22 12:34:39,804] [INFO] [config.py:958:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-10-22 12:34:39,804] [INFO] [config.py:958:print]   bfloat16_config .............. enabled=True immediate_grad_update=False check_grad_overflow=False
[2025-10-22 12:34:39,804] [INFO] [config.py:958:print]   checkpoint_config ............ {'tag_validation': 'WARN', 'checkpoint_serialization': True, 'writer': None}
[2025-10-22 12:34:39,804] [INFO] [config.py:958:print]   checkpoint_parallel_write_pipeline  False
[2025-10-22 12:34:39,804] [INFO] [config.py:958:print]   checkpoint_tag_validation_enabled  True
[2025-10-22 12:34:39,804] [INFO] [config.py:958:print]   checkpoint_tag_validation_fail  False
[2025-10-22 12:34:39,804] [INFO] [config.py:958:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f293d5dee10>
[2025-10-22 12:34:39,804] [INFO] [config.py:958:print]   communication_data_type ...... None
[2025-10-22 12:34:39,804] [INFO] [config.py:958:print]   compile_config ............... deepcompile=False free_activation=False offload_activation=False offload_opt_states=False double_buffer=True symmetric_memory=False debug_log=False offload_parameters=False sync_before_reduce=False sync_after_reduce=False sync_before_allgather=False sync_after_allgather=False keep_int_input_tensors=True keep_all_input_tensors=False
[2025-10-22 12:34:39,804] [INFO] [config.py:958:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-10-22 12:34:39,804] [INFO] [config.py:958:print]   curriculum_enabled_legacy .... False
[2025-10-22 12:34:39,804] [INFO] [config.py:958:print]   curriculum_params_legacy ..... False
[2025-10-22 12:34:39,804] [INFO] [config.py:958:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'pin_memory': False, 'curriculum_learning': {'enabled': False}, 'dynamic_batching': {'enabled': False, 'lr_scaling_method': 'linear', 'min_batch_size': 1, 'max_batch_size': None, 'sequence_picking_order': 'dataloader', 'verbose': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-10-22 12:34:39,804] [INFO] [config.py:958:print]   data_efficiency_enabled ...... False
[2025-10-22 12:34:39,804] [INFO] [config.py:958:print]   dataloader_drop_last ......... False
[2025-10-22 12:34:39,804] [INFO] [config.py:958:print]   disable_allgather ............ False
[2025-10-22 12:34:39,804] [INFO] [config.py:958:print]   dump_state ................... False
[2025-10-22 12:34:39,804] [INFO] [config.py:958:print]   eigenvalue_enabled ........... False
[2025-10-22 12:34:39,804] [INFO] [config.py:958:print]   eigenvalue_gas_boundary_resolution  1
[2025-10-22 12:34:39,804] [INFO] [config.py:958:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-10-22 12:34:39,804] [INFO] [config.py:958:print]   eigenvalue_layer_num ......... 0
[2025-10-22 12:34:39,804] [INFO] [config.py:958:print]   eigenvalue_max_iter .......... 100
[2025-10-22 12:34:39,804] [INFO] [config.py:958:print]   eigenvalue_stability ......... 1e-06
[2025-10-22 12:34:39,804] [INFO] [config.py:958:print]   eigenvalue_tol ............... 0.01
[2025-10-22 12:34:39,804] [INFO] [config.py:958:print]   eigenvalue_verbose ........... False
[2025-10-22 12:34:39,804] [INFO] [config.py:958:print]   elasticity_enabled ........... False
[2025-10-22 12:34:39,804] [INFO] [config.py:958:print]   float16_config ............... enabled=False auto_cast=False loss_scale=0.0 initial_scale_power=16 loss_scale_window=1000 hysteresis=2 consecutive_hysteresis=False min_loss_scale=1 fp16_master_weights_and_grads=False
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   global_rank .................. 0
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   grad_accum_dtype ............. None
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   gradient_accumulation_steps .. 8
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   gradient_clipping ............ 1.0
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   gradient_predivide_factor .... 1.0
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   graph_harvesting ............. False
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   load_universal_checkpoint .... False
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   memory_breakdown ............. False
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   mics_hierarchial_params_gather  False
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   mics_shard_size .............. -1
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   optimizer_legacy_fusion ...... False
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   optimizer_name ............... None
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   optimizer_params ............. None
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   pld_enabled .................. False
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   pld_params ................... False
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   prescale_gradients ........... False
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   scheduler_name ............... None
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   scheduler_params ............. None
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   seq_parallel_communication_data_type  torch.float32
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   sparse_attention ............. None
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   sparse_gradients_enabled ..... False
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   steps_per_print .............. inf
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   tensor_parallel_config ....... dtype=torch.float16 autotp_size=0 tp_overlap_comm=False tensor_parallel=TPConfig(tp_size=1, tp_grain_size=1, mpu=None, tp_group=None) injection_policy_tuple=None keep_module_on_host=False replace_with_kernel_inject=False
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   timers_config ................ enabled=True synchronized=True
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   torch_autocast_dtype ......... None
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   torch_autocast_enabled ....... False
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   torch_autocast_lower_precision_safe_modules  None
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   train_batch_size ............. 32
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   train_micro_batch_size_per_gpu  1
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   use_data_before_expert_parallel_  False
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   use_node_local_storage ....... False
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   wall_clock_breakdown ......... False
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   weight_quantization_config ... None
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   world_size ................... 4
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   zero_allow_untested_optimizer  True
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=500000000 param_persistence_threshold=1000000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False zeropp_loco_param=None mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True log_trace_cache_warnings=False
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   zero_enabled ................. True
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   zero_force_ds_cpu_optimizer .. True
[2025-10-22 12:34:39,805] [INFO] [config.py:958:print]   zero_optimization_stage ...... 2
[2025-10-22 12:34:39,805] [INFO] [config.py:944:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 8, 
    "zero_optimization": {
        "stage": 2, 
        "overlap_comm": true, 
        "contiguous_gradients": true, 
        "reduce_bucket_size": 5.000000e+08, 
        "stage3_prefetch_bucket_size": 5.000000e+08, 
        "stage3_param_persistence_threshold": 1.000000e+06, 
        "gather_16bit_weights_on_model_save": false
    }, 
    "bf16": {
        "enabled": true
    }, 
    "fp16": {
        "enabled": false
    }, 
    "gradient_clipping": 1.0, 
    "wall_clock_breakdown": false, 
    "aio": {
        "block_size": 1.048576e+06, 
        "queue_depth": 8, 
        "single_submit": false, 
        "overlap_events": true
    }, 
    "steps_per_print": inf, 
    "zero_allow_untested_optimizer": true
}
[INFO|trainer.py:2409] 2025-10-22 12:34:39,807 >> ***** Running training *****
[INFO|trainer.py:2410] 2025-10-22 12:34:39,807 >>   Num examples = 1,206
[INFO|trainer.py:2411] 2025-10-22 12:34:39,807 >>   Num Epochs = 6
[INFO|trainer.py:2412] 2025-10-22 12:34:39,807 >>   Instantaneous batch size per device = 1
[INFO|trainer.py:2415] 2025-10-22 12:34:39,807 >>   Total train batch size (w. parallel, distributed & accumulation) = 32
[INFO|trainer.py:2416] 2025-10-22 12:34:39,807 >>   Gradient Accumulation steps = 8
[INFO|trainer.py:2417] 2025-10-22 12:34:39,807 >>   Total optimization steps = 201
[INFO|trainer.py:2418] 2025-10-22 12:34:39,811 >>   Number of trainable parameters = 40,370,176
[INFO|integration_utils.py:832] 2025-10-22 12:34:39,815 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.
wandb: Network error (SSLError), entering retry loop.
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: Network error (SSLError), entering retry loop.
wandb: setting up run wew4i4fj
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/LLaMA-Factory/wandb/run-20251022_123449-wew4i4fj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora
wandb: ⭐️ View project at https://wandb.ai/zhuozhi1997-ucl/llamafactory
wandb: 🚀 View run at https://wandb.ai/zhuozhi1997-ucl/llamafactory/runs/wew4i4fj
  0%|          | 0/201 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
[WARNING|logging.py:328] 2025-10-22 12:36:07,621 >> `use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
  0%|          | 1/201 [02:59<9:59:45, 179.93s/it]  1%|          | 2/201 [06:11<10:18:46, 186.57s/it]  1%|▏         | 3/201 [08:55<9:42:38, 176.56s/it]   2%|▏         | 4/201 [11:27<9:07:36, 166.78s/it]  2%|▏         | 5/201 [14:23<9:15:45, 170.13s/it]                                                  {'loss': 13.3992, 'grad_norm': 18.190196990966797, 'learning_rate': 1.1428571428571429e-05, 'epoch': 0.13}
  2%|▏         | 5/201 [14:23<9:15:45, 170.13s/it]  3%|▎         | 6/201 [17:41<9:43:14, 179.46s/it]  3%|▎         | 7/201 [20:26<9:25:02, 174.75s/it]  4%|▍         | 8/201 [23:15<9:16:35, 173.04s/it]  4%|▍         | 9/201 [26:21<9:26:29, 177.03s/it]mmco: unref short failure
  5%|▍         | 10/201 [29:09<9:14:57, 174.33s/it]                                                   {'loss': 12.632, 'grad_norm': 20.639585494995117, 'learning_rate': 1.9994755690455154e-05, 'epoch': 0.27}
  5%|▍         | 10/201 [29:09<9:14:57, 174.33s/it]mmco: unref short failure
  5%|▌         | 11/201 [31:56<9:04:35, 171.98s/it]  6%|▌         | 12/201 [34:36<8:50:16, 168.34s/it]  6%|▋         | 13/201 [37:34<8:56:32, 171.23s/it]mmco: unref short failure
  7%|▋         | 14/201 [40:06<8:35:46, 165.49s/it]  7%|▋         | 15/201 [43:08<8:48:23, 170.45s/it]                                                   {'loss': 9.3998, 'grad_norm': 8.080683708190918, 'learning_rate': 1.993582036030978e-05, 'epoch': 0.4}
  7%|▋         | 15/201 [43:08<8:48:23, 170.45s/it]  8%|▊         | 16/201 [46:18<9:04:01, 176.44s/it]  8%|▊         | 17/201 [49:11<8:57:33, 175.29s/it]  9%|▉         | 18/201 [51:52<8:41:19, 170.93s/it]  9%|▉         | 19/201 [54:46<8:41:58, 172.08s/it] 10%|▉         | 20/201 [57:53<8:52:31, 176.53s/it]                                                   {'loss': 7.3965, 'grad_norm': 6.331912994384766, 'learning_rate': 1.9811781768982392e-05, 'epoch': 0.53}
 10%|▉         | 20/201 [57:53<8:52:31, 176.53s/it] 10%|█         | 21/201 [1:00:50<8:49:51, 176.62s/it] 11%|█         | 22/201 [1:03:20<8:22:58, 168.60s/it] 11%|█▏        | 23/201 [1:06:09<8:20:17, 168.64s/it] 12%|█▏        | 24/201 [1:09:07<8:25:44, 171.44s/it] 12%|█▏        | 25/201 [1:12:19<8:40:48, 177.55s/it]                                                     {'loss': 6.1484, 'grad_norm': 5.855567932128906, 'learning_rate': 1.9623452664340305e-05, 'epoch': 0.66}
 12%|█▏        | 25/201 [1:12:19<8:40:48, 177.55s/it] 13%|█▎        | 26/201 [1:15:02<8:25:20, 173.26s/it] 13%|█▎        | 27/201 [1:18:02<8:28:06, 175.21s/it] 14%|█▍        | 28/201 [1:21:14<8:40:14, 180.43s/it] 14%|█▍        | 29/201 [1:24:21<8:42:32, 182.28s/it] 15%|█▍        | 30/201 [1:27:08<8:26:39, 177.78s/it]                                                     {'loss': 5.0481, 'grad_norm': 6.250147819519043, 'learning_rate': 1.937206705006344e-05, 'epoch': 0.8}
 15%|█▍        | 30/201 [1:27:08<8:26:39, 177.78s/it] 15%|█▌        | 31/201 [1:30:15<8:31:05, 180.39s/it]mmco: unref short failure
left block unavailable for requested intra mode
error while decoding MB 0 4, bytestream 17866
Invalid NAL unit size (1366204408 > 6381).
missing picture in access unit with size 6385
Invalid NAL unit size (1366204408 > 6381).
Error splitting the input into NAL units.
[mm_plugin] Skip invalid video sample: [Errno 1094995529] Invalid data found when processing input: 'avcodec_send_packet()'; last error log: [h264] Error splitting the input into NAL units.
 16%|█▌        | 32/201 [1:33:10<8:24:18, 179.04s/it] 16%|█▋        | 33/201 [1:35:58<8:11:16, 175.46s/it] 17%|█▋        | 34/201 [1:39:15<8:26:19, 181.91s/it] 17%|█▋        | 35/201 [1:41:57<8:07:28, 176.20s/it]                                                     {'loss': 3.7449, 'grad_norm': 7.397054672241211, 'learning_rate': 1.905927209998447e-05, 'epoch': 0.93}
 17%|█▋        | 35/201 [1:41:57<8:07:28, 176.20s/it] 18%|█▊        | 36/201 [1:44:51<8:02:24, 175.42s/it] 18%|█▊        | 37/201 [1:47:44<7:57:39, 174.76s/it] 19%|█▉        | 38/201 [1:49:25<6:54:45, 152.67s/it] 19%|█▉        | 39/201 [1:52:35<7:21:55, 163.67s/it] 20%|█▉        | 40/201 [1:55:34<7:31:59, 168.45s/it]                                                     {'loss': 2.5102, 'grad_norm': 6.626491069793701, 'learning_rate': 1.8687117365181514e-05, 'epoch': 1.05}
 20%|█▉        | 40/201 [1:55:34<7:31:59, 168.45s/it] 20%|██        | 41/201 [1:58:35<7:38:40, 172.00s/it] 21%|██        | 42/201 [2:01:44<7:49:56, 177.34s/it] 21%|██▏       | 43/201 [2:04:44<7:49:09, 178.16s/it] 22%|██▏       | 44/201 [2:07:24<7:31:19, 172.48s/it] 22%|██▏       | 45/201 [2:10:06<7:20:45, 169.52s/it]                                                     {'loss': 1.9002, 'grad_norm': 5.023441791534424, 'learning_rate': 1.8258041344542567e-05, 'epoch': 1.19}
 22%|██▏       | 45/201 [2:10:06<7:20:45, 169.52s/it] 23%|██▎       | 46/201 [2:12:51<7:14:20, 168.13s/it] 23%|██▎       | 47/201 [2:16:07<7:33:04, 176.52s/it] 24%|██▍       | 48/201 [2:19:18<7:40:49, 180.72s/it] 24%|██▍       | 49/201 [2:22:07<7:28:49, 177.17s/it] 25%|██▍       | 50/201 [2:25:20<7:38:07, 182.04s/it]                                                     {'loss': 1.3325, 'grad_norm': 4.081242084503174, 'learning_rate': 1.7774855506796497e-05, 'epoch': 1.32}
 25%|██▍       | 50/201 [2:25:20<7:38:07, 182.04s/it]left block unavailable for requested intra mode
error while decoding MB 0 4, bytestream 17866
Invalid NAL unit size (1366204408 > 6381).
missing picture in access unit with size 6385
Invalid NAL unit size (1366204408 > 6381).
Error splitting the input into NAL units.
[mm_plugin] Skip invalid video sample: [Errno 1094995529] Invalid data found when processing input: 'avcodec_send_packet()'; last error log: [h264] Error splitting the input into NAL units.
 25%|██▌       | 51/201 [2:28:14<7:28:39, 179.47s/it]mmco: unref short failure
 26%|██▌       | 52/201 [2:31:33<7:40:31, 185.45s/it] 26%|██▋       | 53/201 [2:34:37<7:36:31, 185.07s/it] 27%|██▋       | 54/201 [2:37:20<7:17:04, 178.40s/it] 27%|██▋       | 55/201 [2:40:35<7:26:17, 183.41s/it]                                                     {'loss': 0.8994, 'grad_norm': 2.8197824954986572, 'learning_rate': 1.7240725868704218e-05, 'epoch': 1.45}
 27%|██▋       | 55/201 [2:40:35<7:26:17, 183.41s/it] 28%|██▊       | 56/201 [2:43:54<7:34:14, 187.96s/it] 28%|██▊       | 57/201 [2:46:47<7:20:19, 183.47s/it] 29%|██▉       | 58/201 [2:49:48<7:15:46, 182.84s/it] 29%|██▉       | 59/201 [2:52:42<7:06:41, 180.29s/it] 30%|██▉       | 60/201 [2:55:49<7:08:29, 182.34s/it]                                                     {'loss': 0.579, 'grad_norm': 2.46691632270813, 'learning_rate': 1.665915225011681e-05, 'epoch': 1.58}
 30%|██▉       | 60/201 [2:55:49<7:08:29, 182.34s/it]mmco: unref short failure
 30%|███       | 61/201 [2:58:25<6:47:00, 174.43s/it] 31%|███       | 62/201 [3:01:17<6:42:15, 173.63s/it] 31%|███▏      | 63/201 [3:04:17<6:43:55, 175.62s/it] 32%|███▏      | 64/201 [3:07:12<6:39:58, 175.17s/it] 32%|███▏      | 65/201 [3:10:06<6:36:16, 174.83s/it]                                                     {'loss': 0.3723, 'grad_norm': 2.398805618286133, 'learning_rate': 1.603394534182925e-05, 'epoch': 1.72}
 32%|███▏      | 65/201 [3:10:06<6:36:16, 174.83s/it] 33%|███▎      | 66/201 [3:12:53<6:28:39, 172.74s/it] 33%|███▎      | 67/201 [3:15:38<6:20:06, 170.19s/it] 34%|███▍      | 68/201 [3:18:26<6:16:13, 169.73s/it] 34%|███▍      | 69/201 [3:21:14<6:11:58, 169.08s/it] 35%|███▍      | 70/201 [3:24:29<6:26:19, 176.94s/it]                                                     {'loss': 0.2552, 'grad_norm': 2.0714449882507324, 'learning_rate': 1.536920173648984e-05, 'epoch': 1.85}
 35%|███▍      | 70/201 [3:24:29<6:26:19, 176.94s/it] 35%|███▌      | 71/201 [3:27:30<6:25:56, 178.13s/it] 36%|███▌      | 72/201 [3:30:24<6:20:12, 176.84s/it] 36%|███▋      | 73/201 [3:33:15<6:13:39, 175.16s/it] 37%|███▋      | 74/201 [3:36:20<6:16:55, 178.08s/it] 37%|███▋      | 75/201 [3:39:17<6:13:09, 177.69s/it]                                                     {'loss': 0.1807, 'grad_norm': 0.9591200351715088, 'learning_rate': 1.4669277086172406e-05, 'epoch': 1.98}
 37%|███▋      | 75/201 [3:39:17<6:13:09, 177.69s/it] 38%|███▊      | 76/201 [3:40:45<5:14:26, 150.93s/it] 38%|███▊      | 77/201 [3:44:16<5:48:38, 168.70s/it] 39%|███▉      | 78/201 [3:47:12<5:50:48, 171.12s/it] 39%|███▉      | 79/201 [3:50:23<5:59:43, 176.92s/it] 40%|███▉      | 80/201 [3:53:10<5:50:55, 174.01s/it]                                                     {'loss': 0.1206, 'grad_norm': 0.5896390676498413, 'learning_rate': 1.3938757562492873e-05, 'epoch': 2.11}
 40%|███▉      | 80/201 [3:53:10<5:50:55, 174.01s/it] 40%|████      | 81/201 [3:55:51<5:40:09, 170.08s/it] 41%|████      | 82/201 [3:58:50<5:42:34, 172.72s/it] 41%|████▏     | 83/201 [4:01:45<5:41:00, 173.39s/it] 42%|████▏     | 84/201 [4:04:40<5:39:17, 174.00s/it] 42%|████▏     | 85/201 [4:08:18<6:01:33, 187.02s/it]                                                     {'loss': 0.1095, 'grad_norm': 0.711033046245575, 'learning_rate': 1.3182429806274442e-05, 'epoch': 2.24}
 42%|████▏     | 85/201 [4:08:18<6:01:33, 187.02s/it] 43%|████▎     | 86/201 [4:11:13<5:51:58, 183.64s/it] 43%|████▎     | 87/201 [4:14:19<5:50:16, 184.35s/it] 44%|████▍     | 88/201 [4:17:11<5:39:51, 180.45s/it]mmco: unref short failure
 (repeated 4 more times)
left block unavailable for requested intra mode
error while decoding MB 0 4, bytestream 17866
Invalid NAL unit size (1366204408 > 6381).
missing picture in access unit with size 6385
Invalid NAL unit size (1366204408 > 6381).
Error splitting the input into NAL units.
[mm_plugin] Skip invalid video sample: [Errno 1094995529] Invalid data found when processing input: 'avcodec_send_packet()'; last error log: [h264] Error splitting the input into NAL units.
 44%|████▍     | 89/201 [4:20:01<5:31:03, 177.35s/it] 45%|████▍     | 90/201 [4:23:05<5:31:43, 179.31s/it]                                                     {'loss': 0.085, 'grad_norm': 0.6889016032218933, 'learning_rate': 1.2405249563662539e-05, 'epoch': 2.37}
 45%|████▍     | 90/201 [4:23:05<5:31:43, 179.31s/it] 45%|████▌     | 91/201 [4:25:57<5:25:04, 177.31s/it] 46%|████▌     | 92/201 [4:28:40<5:14:03, 172.87s/it] 46%|████▋     | 93/201 [4:31:38<5:14:09, 174.54s/it]mmco: unref short failure
 47%|████▋     | 94/201 [4:34:34<5:11:51, 174.87s/it] 47%|████▋     | 95/201 [4:37:16<5:02:25, 171.18s/it]                                                     {'loss': 0.0648, 'grad_norm': 0.3702685236930847, 'learning_rate': 1.1612309214197599e-05, 'epoch': 2.5}
 47%|████▋     | 95/201 [4:37:16<5:02:25, 171.18s/it] 48%|████▊     | 96/201 [4:40:20<5:06:07, 174.93s/it] 48%|████▊     | 97/201 [4:43:06<4:58:44, 172.35s/it] 49%|████▉     | 98/201 [4:45:59<4:55:57, 172.41s/it] 49%|████▉     | 99/201 [4:48:47<4:50:46, 171.04s/it] 50%|████▉     | 100/201 [4:51:57<4:57:21, 176.65s/it]                                                      {'loss': 0.0535, 'grad_norm': 0.5632928609848022, 'learning_rate': 1.0808804403614044e-05, 'epoch': 2.64}
 50%|████▉     | 100/201 [4:51:57<4:57:21, 176.65s/it][INFO|trainer.py:3993] 2025-10-22 17:26:55,648 >> Saving model checkpoint to /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-100
/home/CORP/zhuo.zhi/miniconda3/envs/qwen2.5omniemo/lib/python3.12/site-packages/peft/utils/other.py:1228: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /Qwen2.5-Omni-7B/thinker/resolve/main/config.json (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1000)')))"), '(Request ID: de7dae55-8049-4a91-a1ea-7895953fe027)') - silently ignoring the lookup for the file config.json in Qwen2.5-Omni-7B/thinker.
  warnings.warn(
/home/CORP/zhuo.zhi/miniconda3/envs/qwen2.5omniemo/lib/python3.12/site-packages/peft/utils/save_and_load.py:286: UserWarning: Could not find a config file in Qwen2.5-Omni-7B/thinker - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2356] 2025-10-22 17:26:55,908 >> chat template saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-100/chat_template.jinja
[INFO|tokenization_utils_base.py:2525] 2025-10-22 17:26:55,909 >> tokenizer config file saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-100/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-10-22 17:26:55,910 >> Special tokens file saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-100/special_tokens_map.json
[2025-10-22 17:26:56,557] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint global_step100 is begin to save!
[2025-10-22 17:26:56,596] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-100/global_step100/mp_rank_00_model_states.pt
[INFO|image_processing_base.py:260] 2025-10-22 17:26:56,859 >> Image processor saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-100/preprocessor_config.json
[INFO|video_processing_utils.py:491] 2025-10-22 17:26:56,860 >> Video processor saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-100/video_preprocessor_config.json
[INFO|feature_extraction_utils.py:436] 2025-10-22 17:26:56,861 >> Feature extractor saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-100/preprocessor_config.json
[INFO|tokenization_utils_base.py:2356] 2025-10-22 17:26:56,861 >> chat template saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-100/chat_template.jinja
[INFO|tokenization_utils_base.py:2525] 2025-10-22 17:26:56,862 >> tokenizer config file saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-100/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-10-22 17:26:56,862 >> Special tokens file saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-100/special_tokens_map.json
[INFO|processing_utils.py:674] 2025-10-22 17:26:57,540 >> chat template saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-100/chat_template.jinja
 50%|█████     | 101/201 [4:55:14<5:04:43, 182.83s/it] 51%|█████     | 102/201 [4:58:36<5:11:08, 188.57s/it] 51%|█████     | 103/201 [5:01:34<5:02:46, 185.37s/it] 52%|█████▏    | 104/201 [5:04:31<4:55:43, 182.93s/it] 52%|█████▏    | 105/201 [5:07:31<4:51:24, 182.13s/it]                                                      {'loss': 0.0485, 'grad_norm': 0.417732834815979, 'learning_rate': 1e-05, 'epoch': 2.77}
 52%|█████▏    | 105/201 [5:07:31<4:51:24, 182.13s/it] 53%|█████▎    | 106/201 [5:10:41<4:52:02, 184.45s/it] 53%|█████▎    | 107/201 [5:13:34<4:43:23, 180.88s/it] 54%|█████▎    | 108/201 [5:16:32<4:39:04, 180.05s/it] 54%|█████▍    | 109/201 [5:19:14<4:27:47, 174.64s/it] 55%|█████▍    | 110/201 [5:21:53<4:17:39, 169.89s/it]                                                      {'loss': 0.0501, 'grad_norm': 0.5156078934669495, 'learning_rate': 9.19119559638596e-06, 'epoch': 2.9}
 55%|█████▍    | 110/201 [5:21:53<4:17:39, 169.89s/it] 55%|█████▌    | 111/201 [5:24:48<4:17:14, 171.49s/it] 56%|█████▌    | 112/201 [5:27:47<4:17:44, 173.75s/it] 56%|█████▌    | 113/201 [5:30:45<4:16:51, 175.13s/it] 57%|█████▋    | 114/201 [5:32:29<3:43:07, 153.87s/it] 57%|█████▋    | 115/201 [5:35:25<3:49:43, 160.27s/it]                                                      {'loss': 0.0369, 'grad_norm': 0.2767485976219177, 'learning_rate': 8.387690785802403e-06, 'epoch': 3.03}
 57%|█████▋    | 115/201 [5:35:25<3:49:43, 160.27s/it] 58%|█████▊    | 116/201 [5:38:14<3:50:45, 162.88s/it] 58%|█████▊    | 117/201 [5:40:54<3:46:52, 162.05s/it] 59%|█████▊    | 118/201 [5:44:02<3:55:08, 169.98s/it] 59%|█████▉    | 119/201 [5:47:08<3:58:37, 174.61s/it] 60%|█████▉    | 120/201 [5:49:54<3:52:32, 172.26s/it]                                                      {'loss': 0.0324, 'grad_norm': 0.3366023302078247, 'learning_rate': 7.594750436337467e-06, 'epoch': 3.16}
 60%|█████▉    | 120/201 [5:49:54<3:52:32, 172.26s/it] 60%|██████    | 121/201 [5:53:05<3:57:08, 177.86s/it] 61%|██████    | 122/201 [5:56:06<3:55:23, 178.78s/it] 61%|██████    | 123/201 [5:58:52<3:47:19, 174.86s/it] 62%|██████▏   | 124/201 [6:01:52<3:46:22, 176.40s/it] 62%|██████▏   | 125/201 [6:04:51<3:44:16, 177.06s/it]                                                      {'loss': 0.0318, 'grad_norm': 0.29550281167030334, 'learning_rate': 6.8175701937255645e-06, 'epoch': 3.29}
 62%|██████▏   | 125/201 [6:04:51<3:44:16, 177.06s/it] 63%|██████▎   | 126/201 [6:07:39<3:37:55, 174.33s/it] 63%|██████▎   | 127/201 [6:10:40<3:37:42, 176.52s/it] 64%|██████▎   | 128/201 [6:13:41<3:36:18, 177.79s/it] 64%|██████▍   | 129/201 [6:16:46<3:36:06, 180.10s/it] 65%|██████▍   | 130/201 [6:19:54<3:35:50, 182.39s/it]                                                      {'loss': 0.0353, 'grad_norm': 0.3241906762123108, 'learning_rate': 6.061242437507131e-06, 'epoch': 3.43}
 65%|██████▍   | 130/201 [6:19:54<3:35:50, 182.39s/it] 65%|██████▌   | 131/201 [6:22:42<3:27:47, 178.11s/it] 66%|██████▌   | 132/201 [6:25:34<3:22:42, 176.27s/it] 66%|██████▌   | 133/201 [6:28:49<3:25:57, 181.73s/it] 67%|██████▋   | 134/201 [6:31:54<3:24:04, 182.75s/it] 67%|██████▋   | 135/201 [6:34:35<3:13:52, 176.25s/it]                                                      {'loss': 0.0287, 'grad_norm': 0.34209901094436646, 'learning_rate': 5.330722913827594e-06, 'epoch': 3.56}
 67%|██████▋   | 135/201 [6:34:35<3:13:52, 176.25s/it] 68%|██████▊   | 136/201 [6:37:40<3:13:44, 178.83s/it] 68%|██████▊   | 137/201 [6:40:44<3:12:36, 180.56s/it] 69%|██████▊   | 138/201 [6:43:52<3:11:48, 182.67s/it] 69%|██████▉   | 139/201 [6:46:42<3:04:52, 178.91s/it] 70%|██████▉   | 140/201 [6:49:29<2:58:23, 175.46s/it]                                                      {'loss': 0.0293, 'grad_norm': 0.2907952666282654, 'learning_rate': 4.630798263510162e-06, 'epoch': 3.69}
 70%|██████▉   | 140/201 [6:49:29<2:58:23, 175.46s/it] 70%|███████   | 141/201 [6:52:26<2:55:46, 175.78s/it] 71%|███████   | 142/201 [6:55:28<2:54:33, 177.52s/it]mmco: unref short failure
 (repeated 5 more times)
left block unavailable for requested intra mode
error while decoding MB 0 4, bytestream 17866
Invalid NAL unit size (1366204408 > 6381).
missing picture in access unit with size 6385
Invalid NAL unit size (1366204408 > 6381).
Error splitting the input into NAL units.
[mm_plugin] Skip invalid video sample: [Errno 1094995529] Invalid data found when processing input: 'avcodec_send_packet()'; last error log: [h264] Error splitting the input into NAL units.
 71%|███████   | 143/201 [6:58:43<2:56:45, 182.85s/it] 72%|███████▏  | 144/201 [7:01:48<2:54:18, 183.48s/it] 72%|███████▏  | 145/201 [7:04:45<2:49:32, 181.66s/it]                                                      {'loss': 0.0303, 'grad_norm': 0.3081600069999695, 'learning_rate': 3.966054658170754e-06, 'epoch': 3.82}
 72%|███████▏  | 145/201 [7:04:45<2:49:32, 181.66s/it] 73%|███████▎  | 146/201 [7:07:43<2:45:29, 180.54s/it] 73%|███████▎  | 147/201 [7:10:36<2:40:29, 178.32s/it] 74%|███████▎  | 148/201 [7:13:18<2:33:08, 173.36s/it] 74%|███████▍  | 149/201 [7:15:59<2:27:00, 169.63s/it] 75%|███████▍  | 150/201 [7:18:51<2:24:41, 170.22s/it]                                                      {'loss': 0.0286, 'grad_norm': 0.24817758798599243, 'learning_rate': 3.3408477498831917e-06, 'epoch': 3.96}
 75%|███████▍  | 150/201 [7:18:51<2:24:41, 170.22s/it] 75%|███████▌  | 151/201 [7:21:36<2:20:38, 168.76s/it] 76%|███████▌  | 152/201 [7:23:16<2:00:54, 148.04s/it] 76%|███████▌  | 153/201 [7:26:16<2:06:09, 157.70s/it] 77%|███████▋  | 154/201 [7:29:07<2:06:47, 161.86s/it] 77%|███████▋  | 155/201 [7:31:59<2:06:25, 164.91s/it]                                                      {'loss': 0.0248, 'grad_norm': 0.23582102358341217, 'learning_rate': 2.759274131295787e-06, 'epoch': 4.08}
 77%|███████▋  | 155/201 [7:31:59<2:06:25, 164.91s/it] 78%|███████▊  | 156/201 [7:34:56<2:06:19, 168.43s/it] 78%|███████▊  | 157/201 [7:38:25<2:12:31, 180.71s/it] 79%|███████▊  | 158/201 [7:41:16<2:07:23, 177.75s/it] 79%|███████▉  | 159/201 [7:43:52<1:59:52, 171.26s/it] 80%|███████▉  | 160/201 [7:46:42<1:56:42, 170.80s/it]                                                      {'loss': 0.0239, 'grad_norm': 0.25589102506637573, 'learning_rate': 2.2251444932035094e-06, 'epoch': 4.21}
 80%|███████▉  | 160/201 [7:46:42<1:56:42, 170.80s/it] 80%|████████  | 161/201 [7:49:58<1:58:56, 178.42s/it] 81%|████████  | 162/201 [7:52:53<1:55:17, 177.38s/it] 81%|████████  | 163/201 [7:55:32<1:48:50, 171.85s/it] 82%|████████▏ | 164/201 [7:58:18<1:44:48, 169.96s/it] 82%|████████▏ | 165/201 [8:01:00<1:40:35, 167.66s/it]                                                      {'loss': 0.0221, 'grad_norm': 0.26006072759628296, 'learning_rate': 1.7419586554574364e-06, 'epoch': 4.35}
 82%|████████▏ | 165/201 [8:01:00<1:40:35, 167.66s/it] 83%|████████▎ | 166/201 [8:04:01<1:40:05, 171.60s/it] 83%|████████▎ | 167/201 [8:06:58<1:38:06, 173.13s/it] 84%|████████▎ | 168/201 [8:09:43<1:33:59, 170.91s/it] 84%|████████▍ | 169/201 [8:12:27<1:29:58, 168.70s/it] 85%|████████▍ | 170/201 [8:15:22<1:28:09, 170.64s/it]                                                      {'loss': 0.025, 'grad_norm': 0.23445476591587067, 'learning_rate': 1.3128826348184886e-06, 'epoch': 4.48}
 85%|████████▍ | 170/201 [8:15:22<1:28:09, 170.64s/it] 85%|████████▌ | 171/201 [8:18:31<1:28:01, 176.06s/it] 86%|████████▌ | 172/201 [8:21:23<1:24:31, 174.90s/it] 86%|████████▌ | 173/201 [8:24:12<1:20:51, 173.25s/it] 87%|████████▋ | 174/201 [8:26:54<1:16:24, 169.78s/it] 87%|████████▋ | 175/201 [8:29:55<1:14:58, 173.03s/it]                                                      {'loss': 0.0228, 'grad_norm': 0.23447366058826447, 'learning_rate': 9.407279000155311e-07, 'epoch': 4.61}
 87%|████████▋ | 175/201 [8:29:55<1:14:58, 173.03s/it]mmco: unref short failure
 88%|████████▊ | 176/201 [8:33:14<1:15:23, 180.94s/it] 88%|████████▊ | 177/201 [8:36:11<1:11:51, 179.66s/it]mmco: unref short failure
 (repeated 9 more times)
left block unavailable for requested intra mode
error while decoding MB 0 4, bytestream 17866
Invalid NAL unit size (1366204408 > 6381).
missing picture in access unit with size 6385
Invalid NAL unit size (1366204408 > 6381).
Error splitting the input into NAL units.
[mm_plugin] Skip invalid video sample: [Errno 1094995529] Invalid data found when processing input: 'avcodec_send_packet()'; last error log: [h264] Error splitting the input into NAL units.
 89%|████████▊ | 178/201 [8:38:46<1:06:04, 172.38s/it] 89%|████████▉ | 179/201 [8:41:24<1:01:39, 168.16s/it] 90%|████████▉ | 180/201 [8:44:31<1:00:46, 173.63s/it]                                                      {'loss': 0.0263, 'grad_norm': 0.19041495025157928, 'learning_rate': 6.279329499365649e-07, 'epoch': 4.74}
 90%|████████▉ | 180/201 [8:44:31<1:00:46, 173.63s/it] 90%|█████████ | 181/201 [8:47:25<57:57, 173.85s/it]   91%|█████████ | 182/201 [8:50:06<53:49, 169.96s/it] 91%|█████████ | 183/201 [8:53:11<52:22, 174.58s/it] 92%|█████████▏| 184/201 [8:55:48<47:56, 169.18s/it] 92%|█████████▏| 185/201 [8:58:44<45:38, 171.17s/it]                                                    {'loss': 0.0258, 'grad_norm': 0.2500639855861664, 'learning_rate': 3.7654733565969826e-07, 'epoch': 4.88}
 92%|█████████▏| 185/201 [8:58:44<45:38, 171.17s/it] 93%|█████████▎| 186/201 [9:01:39<43:07, 172.47s/it] 93%|█████████▎| 187/201 [9:04:16<39:06, 167.62s/it] 94%|█████████▎| 188/201 [9:07:15<37:03, 171.07s/it] 94%|█████████▍| 189/201 [9:10:20<35:04, 175.35s/it] 95%|█████████▍| 190/201 [9:12:00<27:59, 152.69s/it]                                                    {'loss': 0.0194, 'grad_norm': 0.18460039794445038, 'learning_rate': 1.8821823101760949e-07, 'epoch': 5.0}
 95%|█████████▍| 190/201 [9:12:00<27:59, 152.69s/it] 95%|█████████▌| 191/201 [9:15:04<27:00, 162.03s/it] 96%|█████████▌| 192/201 [9:17:56<24:46, 165.12s/it] 96%|█████████▌| 193/201 [9:20:49<22:19, 167.39s/it] 97%|█████████▋| 194/201 [9:23:38<19:35, 167.86s/it] 97%|█████████▋| 195/201 [9:26:29<16:53, 168.95s/it]                                                    {'loss': 0.0218, 'grad_norm': 0.2820143401622772, 'learning_rate': 6.417963969022389e-08, 'epoch': 5.13}
 97%|█████████▋| 195/201 [9:26:29<16:53, 168.95s/it] 98%|█████████▊| 196/201 [9:29:31<14:24, 172.93s/it] 98%|█████████▊| 197/201 [9:32:46<11:58, 179.52s/it]mmco: unref short failure
 (repeated 9 more times)
left block unavailable for requested intra mode
error while decoding MB 0 4, bytestream 17866
Invalid NAL unit size (1366204408 > 6381).
missing picture in access unit with size 6385
Invalid NAL unit size (1366204408 > 6381).
Error splitting the input into NAL units.
[mm_plugin] Skip invalid video sample: [Errno 1094995529] Invalid data found when processing input: 'avcodec_send_packet()'; last error log: [h264] Error splitting the input into NAL units.
 99%|█████████▊| 198/201 [9:35:36<08:49, 176.52s/it] 99%|█████████▉| 199/201 [9:38:30<05:51, 175.81s/it]mmco: unref short failure
100%|█████████▉| 200/201 [9:41:28<02:56, 176.35s/it]                                                    {'loss': 0.0235, 'grad_norm': 0.243037149310112, 'learning_rate': 5.2443095448506674e-09, 'epoch': 5.27}
100%|█████████▉| 200/201 [9:41:28<02:56, 176.35s/it][INFO|trainer.py:3993] 2025-10-22 22:16:26,766 >> Saving model checkpoint to /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-200
/home/CORP/zhuo.zhi/miniconda3/envs/qwen2.5omniemo/lib/python3.12/site-packages/peft/utils/other.py:1228: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /Qwen2.5-Omni-7B/thinker/resolve/main/config.json (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1000)')))"), '(Request ID: 2ca1a4b5-c4ac-46c2-8e7e-5710abf17f17)') - silently ignoring the lookup for the file config.json in Qwen2.5-Omni-7B/thinker.
  warnings.warn(
/home/CORP/zhuo.zhi/miniconda3/envs/qwen2.5omniemo/lib/python3.12/site-packages/peft/utils/save_and_load.py:286: UserWarning: Could not find a config file in Qwen2.5-Omni-7B/thinker - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2356] 2025-10-22 22:16:26,956 >> chat template saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-200/chat_template.jinja
[INFO|tokenization_utils_base.py:2525] 2025-10-22 22:16:26,957 >> tokenizer config file saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-200/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-10-22 22:16:26,958 >> Special tokens file saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-200/special_tokens_map.json
[2025-10-22 22:16:27,622] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint global_step200 is begin to save!
[2025-10-22 22:16:27,650] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-200/global_step200/mp_rank_00_model_states.pt
[INFO|trainer.py:4102] 2025-10-22 22:16:27,897 >> Deleting older checkpoint [/home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-100] due to args.save_total_limit
[INFO|image_processing_base.py:260] 2025-10-22 22:16:27,907 >> Image processor saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-200/preprocessor_config.json
[INFO|video_processing_utils.py:491] 2025-10-22 22:16:27,908 >> Video processor saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-200/video_preprocessor_config.json
[INFO|feature_extraction_utils.py:436] 2025-10-22 22:16:27,908 >> Feature extractor saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-200/preprocessor_config.json
[INFO|tokenization_utils_base.py:2356] 2025-10-22 22:16:27,909 >> chat template saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-200/chat_template.jinja
[INFO|tokenization_utils_base.py:2525] 2025-10-22 22:16:27,909 >> tokenizer config file saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-200/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-10-22 22:16:27,910 >> Special tokens file saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-200/special_tokens_map.json
[INFO|processing_utils.py:674] 2025-10-22 22:16:28,703 >> chat template saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-200/chat_template.jinja
100%|██████████| 201/201 [9:44:27<00:00, 177.16s/it][INFO|trainer.py:3993] 2025-10-22 22:19:27,831 >> Saving model checkpoint to /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-201
/home/CORP/zhuo.zhi/miniconda3/envs/qwen2.5omniemo/lib/python3.12/site-packages/peft/utils/other.py:1228: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /Qwen2.5-Omni-7B/thinker/resolve/main/config.json (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1000)')))"), '(Request ID: 04b18f92-6a0c-49e8-a166-f643e405a8a2)') - silently ignoring the lookup for the file config.json in Qwen2.5-Omni-7B/thinker.
  warnings.warn(
/home/CORP/zhuo.zhi/miniconda3/envs/qwen2.5omniemo/lib/python3.12/site-packages/peft/utils/save_and_load.py:286: UserWarning: Could not find a config file in Qwen2.5-Omni-7B/thinker - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2356] 2025-10-22 22:19:28,035 >> chat template saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-201/chat_template.jinja
[INFO|tokenization_utils_base.py:2525] 2025-10-22 22:19:28,035 >> tokenizer config file saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-201/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-10-22 22:19:28,036 >> Special tokens file saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-201/special_tokens_map.json
[2025-10-22 22:19:28,517] [INFO] [logging.py:107:log_dist] [Rank 0] [Torch] Checkpoint global_step201 is begin to save!
[2025-10-22 22:19:28,546] [INFO] [logging.py:107:log_dist] [Rank 0] Saving model checkpoint: /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-201/global_step201/mp_rank_00_model_states.pt
[INFO|trainer.py:4102] 2025-10-22 22:19:28,788 >> Deleting older checkpoint [/home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-200] due to args.save_total_limit
[INFO|image_processing_base.py:260] 2025-10-22 22:19:28,871 >> Image processor saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-201/preprocessor_config.json
[INFO|video_processing_utils.py:491] 2025-10-22 22:19:28,871 >> Video processor saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-201/video_preprocessor_config.json
[INFO|feature_extraction_utils.py:436] 2025-10-22 22:19:28,872 >> Feature extractor saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-201/preprocessor_config.json
[INFO|tokenization_utils_base.py:2356] 2025-10-22 22:19:28,873 >> chat template saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-201/chat_template.jinja
[INFO|tokenization_utils_base.py:2525] 2025-10-22 22:19:28,873 >> tokenizer config file saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-201/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-10-22 22:19:28,874 >> Special tokens file saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-201/special_tokens_map.json
[INFO|processing_utils.py:674] 2025-10-22 22:19:29,387 >> chat template saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/checkpoint-201/chat_template.jinja
[INFO|trainer.py:2676] 2025-10-22 22:19:29,388 >> 

Training completed. Do not forget to share your model on huggingface.co/models =)


                                                    {'train_runtime': 35089.5774, 'train_samples_per_second': 0.183, 'train_steps_per_second': 0.006, 'train_loss': 1.6622384460411261, 'epoch': 5.29}
100%|██████████| 201/201 [9:44:38<00:00, 177.16s/it]100%|██████████| 201/201 [9:44:38<00:00, 174.52s/it]
[INFO|image_processing_base.py:260] 2025-10-22 22:19:29,394 >> Image processor saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/preprocessor_config.json
[INFO|video_processing_utils.py:491] 2025-10-22 22:19:29,394 >> Video processor saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/video_preprocessor_config.json
[INFO|feature_extraction_utils.py:436] 2025-10-22 22:19:29,394 >> Feature extractor saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/preprocessor_config.json
[INFO|tokenization_utils_base.py:2356] 2025-10-22 22:19:29,395 >> chat template saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/chat_template.jinja
[INFO|tokenization_utils_base.py:2525] 2025-10-22 22:19:29,395 >> tokenizer config file saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-10-22 22:19:29,395 >> Special tokens file saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/special_tokens_map.json
[INFO|processing_utils.py:674] 2025-10-22 22:19:29,879 >> chat template saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/chat_template.jinja
[INFO|trainer.py:3993] 2025-10-22 22:19:37,118 >> Saving model checkpoint to /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora
/home/CORP/zhuo.zhi/miniconda3/envs/qwen2.5omniemo/lib/python3.12/site-packages/peft/utils/other.py:1228: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError("HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /Qwen2.5-Omni-7B/thinker/resolve/main/config.json (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1000)')))"), '(Request ID: 34f2b35b-6983-4a8b-b28e-e53decd7d17e)') - silently ignoring the lookup for the file config.json in Qwen2.5-Omni-7B/thinker.
  warnings.warn(
/home/CORP/zhuo.zhi/miniconda3/envs/qwen2.5omniemo/lib/python3.12/site-packages/peft/utils/save_and_load.py:286: UserWarning: Could not find a config file in Qwen2.5-Omni-7B/thinker - will assume that the vocabulary was not modified.
  warnings.warn(
[INFO|tokenization_utils_base.py:2356] 2025-10-22 22:19:37,326 >> chat template saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/chat_template.jinja
[INFO|tokenization_utils_base.py:2525] 2025-10-22 22:19:37,327 >> tokenizer config file saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/tokenizer_config.json
[INFO|tokenization_utils_base.py:2534] 2025-10-22 22:19:37,328 >> Special tokens file saved in /home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora/special_tokens_map.json
***** train metrics *****
  epoch                    =       5.2924
  total_flos               = 2313298071GF
  train_loss               =       1.6622
  train_runtime            =   9:44:49.57
  train_samples_per_second =        0.183
  train_steps_per_second   =        0.006
[INFO|modelcard.py:450] 2025-10-22 22:19:38,001 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33m/home/CORP/zhuo.zhi/Project/Qwen2.5-Omni-EMO/output/lemon_omni_lora[0m at: [34m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20251022_123449-wew4i4fj/logs[0m
